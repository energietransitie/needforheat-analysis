{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03f0bdcc-5503-4818-8cca-159a9ba7aabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/twomes-twutility-inverse-grey-box-analysis/src/historicdutchweather/historicdutchweather/main.py:67: DtypeWarning: Columns (15,20,21,22,23,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(url, comment=\"#\", skiprows=30, skip_blank_lines=True, names=__headerline)\n",
      "/home/jovyan/twomes-twutility-inverse-grey-box-analysis/src/historicdutchweather/historicdutchweather/main.py:67: DtypeWarning: Columns (3,4,5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(url, comment=\"#\", skiprows=30, skip_blank_lines=True, names=__headerline)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got a value error for station 258\n",
      "Will skip for now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/twomes-twutility-inverse-grey-box-analysis/src/historicdutchweather/historicdutchweather/main.py:67: DtypeWarning: Columns (3,15,20,21,22,23,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(url, comment=\"#\", skiprows=30, skip_blank_lines=True, names=__headerline)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got a value error for station 275\n",
      "Will skip for now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 2112/2112 [00:29<00:00, 72.18it/s]\n"
     ]
    }
   ],
   "source": [
    "#first we get weather data\n",
    "\n",
    "# before import use pip install git+https://github.com/stephanpcpeters/HourlyHistoricWeather.git#egg=historicdutchweather\n",
    "# or include the following line (without comment) in requirements.txt and run `pip install -r requirements.txt` in a terminal\n",
    "# -e git+https://github.com/stephanpcpeters/HourlyHistoricWeather.git#egg=historicdutchweather\n",
    "import historicdutchweather\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "# firsttest just a short timeseries\n",
    "\n",
    "pseudonym = 886307\n",
    "start = datetime(2021,12, 19)\n",
    "end = datetime(2022, 3, 17)\n",
    "\n",
    "#save dataframe with corresponding pseudonym number\n",
    "file_name = str(pseudonym) + '.xlsx'\n",
    "\n",
    "# utimately: #min, max dates of the analysis\n",
    "# start = datetime(2021,10,21)\n",
    "# stop = datetime(2022,4,30)\n",
    "\n",
    "#location: center of Assendorp neighbourhood in Zwolle\n",
    "lat, lon = 52.5065500000,6.0996100000\n",
    "\n",
    "weather = historicdutchweather.get_local_weather(start, end, lat, lon, metrics=['T', 'FH', 'Q'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3918907-b03a-4bc7-9cd3-c00b3fa620cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use of the database requires the .env file in the root folder of the repo to be filled with the proper credentials\n",
    "\n",
    "import math\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import scipy.optimize\n",
    "import scipy.interpolate\n",
    "\n",
    "import sys\n",
    "sys.path.append('../data/')\n",
    "from extractor import Extractor, Period\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cff266-662e-4ffa-ac7d-6591670b7439",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO functions below can probably be generalized further with functions as parameters\n",
    "\n",
    "def get_home_parameter_timeseries_sum(home: int, parameter: str, seriesname: str, \n",
    "                             differentiate: bool, upsample_to: str, downsample_to: str,\n",
    "                             start: datetime, end: datetime, tz_name_source: str, tz_name_home: str) -> pd.DataFrame:\n",
    "    extractor = Extractor(pseudonym, Period(start, end))\n",
    "    timeseriesdata = extractor.get(parameter)\n",
    "    \n",
    "   \n",
    "    timeseriesdata.set_index('datetime', inplace=True)\n",
    "    if tz_name_source == tz_name_home:\n",
    "        timeseriesdata = timeseriesdata.tz_localize(tz_name_source)\n",
    "    else:\n",
    "        timeseriesdata = timeseriesdata.tz_localize(tz_name_source).tz_convert(tz_name_home)\n",
    "    \n",
    "    #first sort on datetime index\n",
    "    timeseriesdata.sort_index(inplace=True)\n",
    "    #then deduplicate the series\n",
    "    timeseriesdata.drop_duplicates(inplace=True)\n",
    "        \n",
    "    # Converting str to float\n",
    "    timeseriesdata['value'] = timeseriesdata['value'].astype(float)\n",
    "    \n",
    "    timeseriesdata_minute = timeseriesdata.resample(upsample_to).first()\n",
    "    \n",
    "    timeseriesdata_minute.interpolate(method='time', inplace=True)\n",
    "    if differentiate:\n",
    "        timeseriesdata_minute['target_value'] = timeseriesdata_minute['value'].diff().shift(-1)\n",
    "    else:\n",
    "        timeseriesdata_minute['target_value'] = timeseriesdata_minute['value']\n",
    "    timeseriesdata_minute['target_value'] = timeseriesdata_minute['target_value'].fillna(0)\n",
    "    timeseriesdata_minute.rename(columns={'target_value':seriesname}, inplace=True)\n",
    "    timeseriesdata_by_day = timeseriesdata_minute[seriesname].resample(downsample_to).sum()\n",
    "\n",
    "    print(seriesname)\n",
    "    print(timeseriesdata_by_day.describe())\n",
    "\n",
    "    return timeseriesdata_by_day\n",
    "\n",
    "def get_meter_parameter_timeseries_sum(home: int, parameter: str, seriesname: str, \n",
    "                             differentiate: bool, upsample_to: str, downsample_to: str,\n",
    "                             start: datetime, end: datetime, tz_name_source: str, tz_name_home: str) -> pd.DataFrame:\n",
    "    extractor = Extractor(pseudonym, Period(start, end))\n",
    "    timeseriesdata = extractor.get(parameter)\n",
    "    \n",
    "    timeseriesdata.set_index('datetime', inplace=True)\n",
    "    if tz_name_source == tz_name_home:\n",
    "        timeseriesdata = timeseriesdata.tz_localize(tz_name_source)\n",
    "    else:\n",
    "        timeseriesdata = timeseriesdata.tz_localize(tz_name_source).tz_convert(tz_name_home)\n",
    "    \n",
    "    #first sort on datetime index\n",
    "    timeseriesdata.sort_index(inplace=True)\n",
    "    #then deduplicate the series\n",
    "    timeseriesdata.drop_duplicates(inplace=True)\n",
    "    \n",
    "    # Converting str to float\n",
    "    timeseriesdata['value'] = timeseriesdata['value'].astype(float)\n",
    "    \n",
    "\n",
    "    # meter values should always be rising monotonic \n",
    "    # meter value resets, which occasionaly happen, should be removed\n",
    "    # also, small occasional negative meter jumps should be ignored\n",
    "    # so first calculate diff, filter out the negative jumps and recalculate the meter value, starting at zero\n",
    "    timeseriesdata['value'] = timeseriesdata['value'].diff().fillna(0).clip(0,None).cumsum()\n",
    "\n",
    "\n",
    "    timeseriesdata_minute = timeseriesdata.resample(upsample_to).first()\n",
    "    timeseriesdata_minute.interpolate(method='time', inplace=True)\n",
    "    if differentiate:\n",
    "        timeseriesdata_minute['target_value'] = timeseriesdata_minute['value'].diff().shift(-1)\n",
    "    else:\n",
    "        timeseriesdata_minute['target_value'] = timeseriesdata_minute['value']\n",
    "    timeseriesdata_minute['target_value'] = timeseriesdata_minute['target_value'].fillna(0)\n",
    "    timeseriesdata_minute.rename(columns={'target_value':seriesname}, inplace=True)\n",
    "    timeseriesdata_by_day = timeseriesdata_minute[seriesname].resample(downsample_to).sum()\n",
    "\n",
    "    print(seriesname)\n",
    "    print(timeseriesdata_by_day.describe())\n",
    "\n",
    "    return timeseriesdata_by_day\n",
    "\n",
    "def get_home_parameter_timeseries_count(home: int, parameter: str, seriesname: str, \n",
    "                             differentiate: bool, upsample_to: str, downsample_to: str,\n",
    "                             start: datetime, end: datetime, tz_name_source: str, tz_name_home: str) -> pd.DataFrame:\n",
    "    extractor = Extractor(pseudonym, Period(start, end))\n",
    "    timeseriesdata = extractor.get(parameter)\n",
    "    \n",
    "    timeseriesdata.set_index('datetime', inplace=True)\n",
    "    if tz_name_source == tz_name_home:\n",
    "        timeseriesdata = timeseriesdata.tz_localize(tz_name_source)\n",
    "    else:\n",
    "        timeseriesdata = timeseriesdata.tz_localize(tz_name_source).tz_convert(tz_name_home)\n",
    "\n",
    "    #first sort on datetime index\n",
    "    timeseriesdata.sort_index(inplace=True)\n",
    "    #then deduplicate the series\n",
    "    timeseriesdata.drop_duplicates(inplace=True)\n",
    "\n",
    "    # Converting str to float\n",
    "    timeseriesdata['value'] = timeseriesdata['value'].astype(float)\n",
    "    \n",
    "    timeseriesdata_minute = timeseriesdata.resample(upsample_to).first()\n",
    "    timeseriesdata_minute.interpolate(method='time', inplace=True)\n",
    "    if differentiate:\n",
    "        timeseriesdata_minute['target_value'] = timeseriesdata_minute['value'].diff().shift(-1)\n",
    "    else:\n",
    "        timeseriesdata_minute['target_value'] = timeseriesdata_minute['value']\n",
    "    timeseriesdata_minute['target_value'] = timeseriesdata_minute['target_value'].fillna(0)\n",
    "    timeseriesdata_minute.rename(columns={'target_value':seriesname}, inplace=True)\n",
    "    timeseriesdata_by_day = timeseriesdata_minute[seriesname].resample(downsample_to).count()\n",
    "\n",
    "    print(seriesname)\n",
    "    print(timeseriesdata_by_day.describe())\n",
    "\n",
    "    return timeseriesdata_by_day\n",
    "\n",
    "def get_home_parameter_timeseries_mean(home: int, parameter: str, seriesname: str, \n",
    "                             upsample_to: str, downsample_to: str,\n",
    "                             start: datetime, end: datetime, tz_name_source: str, tz_name_home: str) -> pd.DataFrame:\n",
    "    extractor = Extractor(pseudonym, Period(start, end))\n",
    "    timeseriesdata = extractor.get(parameter)\n",
    "    \n",
    "    timeseriesdata.set_index('datetime', inplace=True)\n",
    "    if tz_name_source == tz_name_home:\n",
    "        timeseriesdata = timeseriesdata.tz_localize(tz_name_source)\n",
    "    else:\n",
    "        timeseriesdata = timeseriesdata.tz_localize(tz_name_source).tz_convert(tz_name_home)\n",
    "    \n",
    "    ####\n",
    "    # below unsuccesfull way to calculate duration weithed average\n",
    "    # timeseriesdata['wt'] = timeseriesdata['timedelta'].dt.total_seconds()\n",
    "    # the NumPy function average can be used to calculate a duration-weighted average across a pandas dataframe\n",
    "    # np.average(timeseriesdata.value, weights=timeseriesdata.wt)\n",
    "    # oddly enough, this function cannot be used in a lambda function while resampling a dataframe with a DatetimeIndex?!\n",
    "\n",
    "    # remove the # before the next line to try..\n",
    "    # timeseriesdata.resample('1D').apply(lambda x : np.average(x.value, weights=x.wt))\n",
    "    ####\n",
    "\n",
    "    #first sort on datetime index\n",
    "    timeseriesdata.sort_index(inplace=True)\n",
    "    #then deduplicate the series\n",
    "    timeseriesdata.drop_duplicates(inplace=True)\n",
    "\n",
    "    # Converting str to float\n",
    "    timeseriesdata['value'] = timeseriesdata['value'].astype(float)\n",
    "    \n",
    "    timeseriesdata_minute = timeseriesdata.resample(upsample_to).first()\n",
    "    timeseriesdata_minute.interpolate(method='time', inplace=True)\n",
    "    timeseriesdata_minute['target_value'] = timeseriesdata_minute['value'].fillna(0)\n",
    "    timeseriesdata_minute.rename(columns={'target_value':seriesname}, inplace=True)\n",
    "    timeseriesdata_by_day = timeseriesdata_minute[seriesname].resample(downsample_to).mean()\n",
    "\n",
    "    print(seriesname)\n",
    "    print(timeseriesdata_by_day.describe())\n",
    "\n",
    "    return timeseriesdata_by_day\n",
    "\n",
    "\n",
    "def get_indoor_setpoint_timeseries_mean(home: int, parameter: str, seriesname: str,  \n",
    "                             upsample_to: str, downsample_to: str,\n",
    "                             start: datetime, end: datetime, tz_name_source: str, tz_name_home: str) -> pd.DataFrame:\n",
    "    extractor = Extractor(pseudonym, Period(start, end))\n",
    "    timeseriesdata = extractor.get(parameter)\n",
    "    \n",
    "    timeseriesdata.set_index('datetime', inplace=True)\n",
    "    if tz_name_source == tz_name_home:\n",
    "        timeseriesdata = timeseriesdata.tz_localize(tz_name_source)\n",
    "    else:\n",
    "        timeseriesdata = timeseriesdata.tz_localize(tz_name_source).tz_convert(tz_name_home)\n",
    "    \n",
    "    #first sort on datetime index\n",
    "    timeseriesdata.sort_index(inplace=True)\n",
    "    #then deduplicate the series\n",
    "    timeseriesdata.drop_duplicates(inplace=True)\n",
    "    \n",
    "    # Converting str to float\n",
    "    timeseriesdata['value'] = timeseriesdata['value'].astype(float)\n",
    "    \n",
    "    #now, first recalculate the value; make sure only integer values are supplied to to_deg_C function\n",
    "    # timeseriesdata['value'] = timeseriesdata['value'].apply(lambda x:  to_degC(int(x)))\n",
    "    \n",
    "    timeseriesdata_minute = timeseriesdata.resample(upsample_to).first()\n",
    "    timeseriesdata_minute.interpolate(method='time', inplace=True)\n",
    "    timeseriesdata_minute['target_value'] = timeseriesdata_minute['value'].fillna(0)\n",
    "    timeseriesdata_minute.rename(columns={'target_value':seriesname}, inplace=True)\n",
    "    timeseriesdata_by_day = timeseriesdata_minute[seriesname].resample(downsample_to).mean()\n",
    "\n",
    "    print(seriesname)\n",
    "    print(timeseriesdata_by_day.describe())\n",
    "\n",
    "    return timeseriesdata_by_day\n",
    "\n",
    "\n",
    "print (\"Done defining convenience functions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9235e9-bcdd-41ec-a2af-5bb808b88552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather_parameter_timeseries_mean(home: int, parameter: str, seriesname: str, \n",
    "                             upsample_to: str, downsample_to: str,\n",
    "                             start: datetime, end: datetime, tz_name_source: str, tz_name_home: str) -> pd.DataFrame:\n",
    "\n",
    "    timeseriesdata = pd.DataFrame(weather[parameter])\n",
    "    print(timeseriesdata)\n",
    "    # timeseriesdata.set_index('datetime', inplace=True)\n",
    "\n",
    "    if not(tz_name_source == tz_name_home):\n",
    "        timeseriesdata = timeseriesdata.tz_convert(tz_name_home)\n",
    "\n",
    "    #first sort on datetime index\n",
    "    timeseriesdata.sort_index(inplace=True)\n",
    "    #then deduplicate the series\n",
    "    timeseriesdata.drop_duplicates(inplace=True)\n",
    "\n",
    "    # Converting str to float\n",
    "    # timeseriesdata[parameter] = timeseriesdata[parameter].astype(float)\n",
    "    \n",
    "    timeseriesdata_minute = timeseriesdata.resample(upsample_to).first()\n",
    "\n",
    "    \n",
    "    timeseriesdata_minute.interpolate(method='time', inplace=True)\n",
    "    timeseriesdata_minute['target_value'] = timeseriesdata_minute[parameter].fillna(0)\n",
    "    timeseriesdata_minute.rename(columns={'target_value':seriesname}, inplace=True)\n",
    "    timeseriesdata_by_day = timeseriesdata_minute[seriesname].resample(downsample_to).mean()\n",
    "\n",
    "    print(seriesname)\n",
    "    print(timeseriesdata_by_day.describe())\n",
    "\n",
    "    return timeseriesdata_by_day\n",
    "\n",
    "print (\"Done defining weather convenience functions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e493611-d10b-4ba3-a2e3-4e4917b83590",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "\n",
    "upsample = '5min'\n",
    "downsample = '15min'\n",
    "tz_source = 'UTC'\n",
    "tz_home = 'Europe/Amsterdam'\n",
    "\n",
    "\n",
    "print('Resampling weather data...' )\n",
    "#N.B. weather data is now retrieved from weather dataframe, datetimestamps are ' UTC' \n",
    "print('... outdoor_temp_degC' )\n",
    "outdoor_temp_by_day = get_weather_parameter_timeseries_mean(pseudonym, 'T', 'outdoor_temp_degC', \n",
    "                                                            upsample, downsample, start, end, tz_source, tz_home)\n",
    "print('... windspeed_m_per_s' )\n",
    "windspeed_by_day = get_weather_parameter_timeseries_mean(pseudonym, 'FH', 'windspeed_m_per_s', \n",
    "                                                            upsample, downsample, start, end, tz_source, tz_home)\n",
    "print('... hor_irradiation_J_per_h_per_m^2' )\n",
    "irradiation_by_day = get_weather_parameter_timeseries_mean(pseudonym, 'Q', 'hor_irradiation_J_per_h_per_m^2', \n",
    "                                                            upsample, downsample, start, end, tz_source, tz_home)\n",
    "\n",
    "# merge weather data in a single dataframe\n",
    "weather_by_day = pd.concat([outdoor_temp_by_day, windspeed_by_day, irradiation_by_day], axis=1, join='outer') \n",
    "#calculate effective outdoor temperature based on KNMI formula\n",
    "weather_by_day['effective_outdoor_temp_degC'] = weather_by_day['outdoor_temp_degC'] - 2/3 * weather_by_day['windspeed_m_per_s'] \n",
    "\n",
    "weather_by_day['hor_irradiation_W_per_m^2'] = weather_by_day['hor_irradiation_J_per_h_per_m^2']  / (60 * 60)\n",
    "\n",
    "\n",
    "data_by_day_total = pd.DataFrame()\n",
    "\n",
    "print('Retrieving data for pseudonym...' )\n",
    "\n",
    "\n",
    "# TODO:convert list of pseudonyms to function call that uses database, something like \n",
    "# pseudonymlist = extractor.get_accounts()\n",
    "\n",
    "# for pseudonym in [901216, 912336, 917629, 918349, 919110, 921286, 921767, 922325, 928292, 934457, \n",
    "#                    935323, 935869, 937111, 940703, 940957, 944008, 944999, 946938, 951667, 952553, \n",
    "#                    956719, 959010, 959403, 959885, 962398, 965160, 970156, 971591, 973327, 973834, \n",
    "#                    978454, 983811, 983987, 986699, 986715, 988752, 990642, 991561, 991990, 992752, \n",
    "#                    992890, 993143, 993705, 999071, 999749, 999890]:\n",
    "\n",
    "# for pseudonym in [944008, 901216, 986715]:\n",
    "\n",
    "print(pseudonym)\n",
    "\n",
    "print('...getting heartbeat')\n",
    "heartbeats_by_day = get_home_parameter_timeseries_count(pseudonym, 'heartbeat', 'heartbeat', False, upsample, downsample, start, end, tz_source, tz_home)\n",
    "    \n",
    "print('...getting indoor_temp_degC')\n",
    "indoor_temp_by_day = get_home_parameter_timeseries_mean(pseudonym, 'roomTemp', 'indoor_temp_degC', \n",
    "                                                            upsample, downsample, start, end, tz_source, tz_home)\n",
    "    \n",
    "print('...getting indoor_temp_degC_CO2')\n",
    "indoor_temp_by_day_CO2 = get_home_parameter_timeseries_mean(pseudonym, 'roomTempCO2', 'indoor_temp_degC_CO2', \n",
    "                                                            upsample, downsample, start, end, tz_source, tz_home)  \n",
    "    \n",
    "print('...getting indoor_setpoint_temp_degC')\n",
    "indoor_setpoint_by_day = get_indoor_setpoint_timeseries_mean(pseudonym,'roomSetpointTemp', 'indoor_setpoint_temp_degC',\n",
    "                                                            upsample, downsample, start, end, tz_source, tz_home)\n",
    "if len(indoor_temp_by_day.index)>=1:\n",
    "    print('...getting gas_m^3')\n",
    "    gas_m3_by_day = get_meter_parameter_timeseries_sum(pseudonym, 'gMeterReadingSupply', 'gas_m^3', \n",
    "                                         True, upsample, downsample, start, end, tz_source, tz_home)\n",
    "#         heatpump_kwh_by_day = get_meter_parameter_timeseries_sum(pseudonym, 'EnergyCentralHeating', 'heatpump_kWh', \n",
    "#                                          True, upsample, downsample, start, end, tz_source, tz_home)\n",
    "#         pv_yield_kwh_by_day = get_meter_parameter_timeseries_sum(pseudonym, 'PVYield', 'pv_yield_kWh', \n",
    "#                                          True, upsample, downsample, start, end, tz_source, tz_home)\n",
    "#         pv_used_kwh_by_day = get_meter_parameter_timeseries_sum(pseudonym, 'PVUsed', 'pv_used_kWh', \n",
    "#                                          True, upsample, downsample, start, end, tz_source, tz_home)\n",
    "    print('...getting e_used_normal_kWh')\n",
    "    e_used_normal_kWh_by_day = get_meter_parameter_timeseries_sum(pseudonym, 'eMeterReadingSupplyHigh', 'e_used_normal_kWh', \n",
    "                                         True, upsample, downsample, start, end, tz_source, tz_home)\n",
    "    print('...getting e_used_low_kWh')\n",
    "    e_used_low_kWh_by_day = get_meter_parameter_timeseries_sum(pseudonym, 'eMeterReadingSupplyLow', 'e_used_low_kWh', \n",
    "                                         True, upsample, downsample, start, end, tz_source, tz_home)\n",
    "    print('...getting e_returned_normal_kWh')\n",
    "    e_returned_normal_kWh_by_day = get_meter_parameter_timeseries_sum(pseudonym, 'eMeterReadingReturnHigh', 'e_returned_normal_kWh', \n",
    "                                         True, upsample, downsample, start, end, tz_source, tz_home)\n",
    "    print('...getting e_returned_low_kWh')\n",
    "    e_returned_low_kWh_by_day = get_meter_parameter_timeseries_sum(pseudonym, 'eMeterReadingReturnLow', 'e_returned_low_kWh', \n",
    "                                         True, upsample, downsample, start, end, tz_source, tz_home)\n",
    "#         dhw_m3_by_day = get_meter_parameter_timeseries_sum(pseudonym, 'DHWVolume', 'dhw_m^3', \n",
    "#                                          True, upsample, downsample, start, end, tz_source, tz_home)\n",
    "\n",
    "#         home_by_day = pd.concat([heartbeats_by_day, weather_by_day ,indoor_temp_by_day, indoor_temp_by_day_CO2, \n",
    "#                                  indoor_setpoint_by_day,\n",
    "#                                  gas_m3_by_day,\n",
    "#                                  e_used_normal_kWh_by_day, e_used_low_kWh_by_day,\n",
    "#                                  e_returned_normal_kWh_by_day, e_returned_low_kWh_by_day\n",
    "#                                 ], axis=1, join='outer')\n",
    "    \n",
    "    home_by_day = pd.concat([heartbeats_by_day, weather_by_day, indoor_temp_by_day, indoor_temp_by_day_CO2, \n",
    "                                 indoor_setpoint_by_day,\n",
    "                                 gas_m3_by_day,\n",
    "                                 e_used_normal_kWh_by_day, e_used_low_kWh_by_day,\n",
    "                                 e_returned_normal_kWh_by_day, e_returned_low_kWh_by_day\n",
    "                                ], axis=1, join='outer')    \n",
    "    \n",
    "    home_by_day['homepseudonym'] = pseudonym\n",
    "        \n",
    "        # do not include horizontal irradiation in exports for Bouwkunde\n",
    "        #data_by_day = home_by_day.reindex(columns= ['homepseudonym', 'outdoor_temp_degC', 'windspeed_m_per_s', 'hor_irradiation_W_per_m^2', 'eff_outdoor_temp_degC', 'indoor_temp_degC', 'gasvolume_m^3', 'heatpump_kWh'])\n",
    "\n",
    "#         data_by_day = home_by_day.reindex(columns= ['homepseudonym', 'heartbeat',\n",
    "#                                                     'outdoor_temp_degC','windspeed_m_per_s', 'effective_outdoor_temp_degC', \n",
    "#                                                     'indoor_temp_degC', 'indoor_setpoint_temp_degC', 'gas_m^3', 'heatpump_kWh', \n",
    "#                                                     'pv_yield_kWh', 'pv_used_kWh', \n",
    "#                                                     'e_used_normal_kWh', 'e_used_low_kWh', \n",
    "#                                                     'e_returned_normal_kWh', 'e_returned_low_kWh', \n",
    "#                                                     'dhw_m^3'])\n",
    "        \n",
    "    data_by_day = home_by_day.reindex(columns= ['homepseudonym', 'heartbeat',\n",
    "                                                    'outdoor_temp_degC','windspeed_m_per_s', 'effective_outdoor_temp_degC', 'hor_irradiation_J_per_h_per_m^2',  \n",
    "                                                    'indoor_temp_degC', 'indoor_temp_degC_CO2', 'indoor_setpoint_temp_degC',\n",
    "                                                    'gas_m^3',  \n",
    "                                                    'e_used_normal_kWh', 'e_used_low_kWh', \n",
    "                                                    'e_returned_normal_kWh', 'e_returned_low_kWh'\n",
    "                                                   ])\n",
    "                \n",
    "        \n",
    "    data_by_day['timedelta'] = data_by_day.index.to_series().diff().shift(-1)\n",
    "    data_by_day['timedelta_s'] = data_by_day['timedelta'].apply(lambda x: x.total_seconds())\n",
    "\n",
    "        \n",
    "    data_by_day_total = pd.concat([data_by_day_total, data_by_day], axis=0)\n",
    "#         data_by_day_total['heat_demand_Ks'] = (data_by_day_total['indoor_temp_degC'] - data_by_day_total['outdoor_temp_degC']) * data_by_day_total['timedelta_s']\n",
    "#         data_by_day_total['effective_heat_demand_Ks'] = (data_by_day_total['indoor_temp_degC'] - data_by_day_total['effective_outdoor_temp_degC']) * data_by_day_total['timedelta_s']\n",
    "#         data_by_day_total['e_used_net_kWh'] = (data_by_day_total['e_used_normal_kWh'] + data_by_day_total['e_used_low_kWh'] - data_by_day_total['e_returned_normal_kWh'] - data_by_day_total['e_returned_low_kWh'] + data_by_day_total['pv_yield_kWh'] - data_by_day_total['pv_used_kWh'])\n",
    "    data_by_day_total['e_used_net_kWh'] = (data_by_day_total['e_used_normal_kWh'] + data_by_day_total['e_used_low_kWh'] - data_by_day_total['e_returned_normal_kWh'] - data_by_day_total['e_returned_low_kWh'])\n",
    "        \n",
    "#         data_by_day_total['e_remaining_heat_kWh'] = (data_by_day_total['e_used_net_kWh'] - data_by_day_total['heatpump_kWh'])\n",
    "    data_by_day_total['e_remaining_heat_kWh'] = (data_by_day_total['e_used_net_kWh'])\n",
    "\n",
    "    data_by_day_total['daycompleteness'] = (data_by_day_total['heartbeat'] / data_by_day_total['timedelta_s'] * 60 * 5)\n",
    "\n",
    "#         filename = './'+str(pseudonym)+'.xlsx'\n",
    "#         #strip timezone info before exporting to (Excel doet not support timezone)\n",
    "#         data_by_day.tz_localize(None).to_excel(filename)\n",
    "        \n",
    "# data_by_day_total.tz_localize(None, level=0).to_excel('./allhomes.xlsx')\n",
    "print(data_by_day_total.describe())\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756a7bb4-492a-48bd-bd93-108a53224297",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_by_day_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6a7cc9-5d35-4810-b167-13c3a289a1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot retrieved data\n",
    "\n",
    "property = 'indoor_temp_degC'\n",
    "\n",
    "%matplotlib widget\n",
    "import pylab as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.grid(True)\n",
    "# ax.xaxis.grid(True)\n",
    "# ax.yaxis.grid(True)\n",
    "\n",
    "\n",
    "ax2 = ax.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "ax2.set_ylabel(r'$I\\ [J/(h \\bullet m^2)]$')\n",
    "ax2.plot(weather.index, weather['Q'], '.', label='global horizontal irradiation', alpha=0.5, color='y')  # ... and some more.\n",
    "ax2.legend(loc=1)\n",
    "\n",
    "ax.plot(data_by_day.index, data_by_day['outdoor_temp_degC'], '.', label='outdoor temperature', color='r')  # Plot some data on the axes.\n",
    "ax.plot(data_by_day.index, data_by_day['windspeed_m_per_s'], '.', label='wind speed', color='c')  # Plot more data on the axes...\n",
    "ax.plot(data_by_day.index, data_by_day['effective_outdoor_temp_degC'], '.', label='effective outdoor temperature', color='orange')  # Plot more data on the axes...\n",
    "ax.plot(data_by_day.index, data_by_day[property], '.', label=property, color='b')  # Plot some data on the axes.\n",
    "ax.legend(loc=0);  # Add a legend.\n",
    "\n",
    "ax.set_xlabel('Date & time')  # Add an x-label to the axes.\n",
    "ax.set_ylabel(r'$T_{out} [^oC], U [m/s]$')\n",
    "plt.show()\n",
    "\n",
    "# N.B. The resulting figure below can be manipulated interactively; hover with mouse for tips & tricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e069669-e17e-4bac-8820-e9b1b57fbc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy dataframe + add index column + change the name of \"datetime obj\"\n",
    "\n",
    "df = data_by_day_total.copy()\n",
    "df = df.reset_index()\n",
    "df.rename(columns={'index': 'Date_Time'}, inplace=True)\n",
    "df['index_col'] = df.index\n",
    "delta_t = int(df['timedelta_s'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b9912a-60d8-4994-9e1a-e1353ac05b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date_Time'] = df['Date_Time'].dt.tz_localize(None)\n",
    "df.to_excel(file_name)\n",
    "\n",
    "result_per_home_df = pd.DataFrame(columns=['pseudonym', 'start_point', 'end_point','duration [days]' ,'tau [h]', 'H [W/K]', 'A_eff [m^2]', 'COP_CH', 'eta_hs_CH'])\n",
    "\n",
    "# total_result_df = pd.DataFrame(columns=['pseudonym', 'start_point', 'end_point','duration [days]' ,'tau [h]', 'H [W/K]', 'A_eff [m^2]', 'COP_CH', 'eta_hs_CH'])\n",
    "# result_per_home_df.to_excel('result.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3961f1d7-7bc1-44dc-8b50-b5fbd2d9788e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gekko import GEKKO\n",
    "end_point = df.index[df['Date_Time'] == '2021-12-19 01:00:00'].tolist()[0]\n",
    "\n",
    "duration = 7\n",
    "num_iter = 11\n",
    "printing_row = 11\n",
    "\n",
    "for j in range(num_iter):\n",
    "    start_point = end_point\n",
    "    end_point = start_point + (duration * 24 * 4)\n",
    "\n",
    "    # data loading\n",
    "    setpoint = np.asarray(df['indoor_setpoint_temp_degC'].iloc[start_point:end_point])\n",
    "\n",
    "    T_in_meas = np.asarray(df['indoor_temp_degC'].iloc[start_point:end_point])\n",
    "    T_out_eff_arr = np.asarray(df['effective_outdoor_temp_degC'].iloc[start_point:end_point])\n",
    "    time_recorded = df['Date_Time'].iloc[start_point:end_point]\n",
    "    T_out = np.asarray(df['outdoor_temp_degC'].iloc[start_point:end_point])\n",
    "    gas_total = np.asarray(df['gas_m^3'].iloc[start_point:end_point])\n",
    "\n",
    "    e_used_normal_val = np.asarray(df['e_used_normal_kWh'].iloc[start_point:end_point])\n",
    "    e_used_low_val = np.asarray(df['e_used_low_kWh'].iloc[start_point:end_point])\n",
    "\n",
    "#     pv_yield_val = np.asarray(df['pv_yield_kWh'].iloc[start_point:end_point])\n",
    "#     pv_used_val = np.asarray(df['pv_used_kWh'].iloc[start_point:end_point])\n",
    "\n",
    "    e_returned_normal_val = np.asarray(df['e_returned_normal_kWh'].iloc[start_point:end_point])\n",
    "    e_returned_low_val = np.asarray(df['e_returned_low_kWh'].iloc[start_point:end_point])\n",
    "\n",
    "    delta_E_supply_val = np.asarray(e_used_normal_val + e_used_low_val)\n",
    "    \n",
    "#     delta_E_PV_val = np.asarray(pv_yield_val - pv_used_val)\n",
    "    delta_E_PV_val = 0\n",
    "    \n",
    "    delta_E_ret_val = np.asarray(e_returned_normal_val + e_returned_low_val)\n",
    "    delta_EV_charge_val = 0\n",
    "\n",
    "#     delta_E_CH_val = np.asarray(df['heatpump_kWh'].iloc[start_point:end_point])\n",
    "    delta_E_CH_val = 0\n",
    "\n",
    "\n",
    "    delta_E_int_val = np.asarray(\n",
    "        (delta_E_supply_val + delta_E_PV_val - delta_E_ret_val - delta_EV_charge_val - delta_E_CH_val) / delta_t)   # [kWh/s]\n",
    "    delta_Q_int_e_val = np.asarray(delta_E_int_val * 1000 * 60 * 60)    # [W]\n",
    "    I_geo_eff_val = np.asarray(df['hor_irradiation_J_per_h_per_m^2'].iloc[start_point:end_point])\n",
    "\n",
    "    ########################################################################################################################\n",
    "    #                                                   tau initial values input\n",
    "    ########################################################################################################################\n",
    "    # tau Input: the following value should be based on hour for tau [hr]\n",
    "    tau_init_val_hr = 100\n",
    "    tau_lb_hr = 10\n",
    "    tau_ub_hr = 1000\n",
    "\n",
    "    # Internal conversion (do not change this part)\n",
    "    tau_init_val = tau_init_val_hr * 3600\n",
    "    tau_lb = tau_lb_hr * 3600\n",
    "    tau_ub = tau_ub_hr * 3600\n",
    "\n",
    "    ########################################################################################################################\n",
    "    #                                                   Gekko Model - Initialize\n",
    "    ########################################################################################################################\n",
    "    # initialize gekko\n",
    "    m = GEKKO(remote=False)\n",
    "    m.time = np.linspace(delta_t, len(T_in_meas) * delta_t, len(T_in_meas))  # [s]\n",
    "\n",
    "    ########################################################################################################################\n",
    "    #                                                   Gekko Model - Variables\n",
    "    ########################################################################################################################\n",
    "    \"\"\"\"\n",
    "    Model parameter:\n",
    "    tau [hr]: effective thermal inertia\n",
    "    eta_hs_CH [-]: upper heating efficiency of the central heating system\n",
    "    COP_CH [-]: Coef. of Performance for heat pump\n",
    "    H [W/K]: specific heat loss\n",
    "    A_eff [m^2]: Effective area of the imaginary solar aperture in the horizontal plane\n",
    "    \"\"\"\n",
    "    tau = m.FV(value=tau_init_val, lb=tau_lb, ub=tau_ub);\n",
    "    tau.STATUS = 1;\n",
    "    tau.FSTATUS = 0;  # tau.DMAX = 10\n",
    "    H = m.FV(value=300.0, lb=0, ub=1000);\n",
    "    H.STATUS = 1;\n",
    "    H.FSTATUS = 0;  # H.DMAX=50                #[W/K]\n",
    "    # eta_hs_CH = m.FV(value=0.8, lb=0, ub=1.0); eta_hs_CH.STATUS = 1; eta_hs_CH.FSTATUS = 0;  # eta_hs_CH.DMAX = 0.25\n",
    "    # COP_CH = m.FV(value=1, lb=0.1, ub=7) ; COP_CH.STATUS = 1 ; COP_CH.FSTATUS = 0 ; #COP_CH.DMAX=1\n",
    "    # A_eff = m.FV(value=5, lb=1, ub=100) ; A_eff.STATUS = 1 ; A_eff.FSTATUS = 0            #[m^2]\n",
    "\n",
    "    \"\"\"\"\n",
    "    Constant parameter:\n",
    "    h_E [J/kWh]: Convertion factor ( [kWh] to [J] ) = 1000 * 60 * 60\n",
    "\n",
    "    h_sup [J/Nm^3]: superior calorific value of natural gas from the Groningen field = 35,170,000.00\n",
    "    eta_hs_noCH [-]: upper efficiency of heating the home indirectly using gas, for other primary purposes than heating the home\n",
    "\n",
    "    delta_Q_sol [J/s]: heat gain from solar irradiation\n",
    "    delta_G_noCH [Nm^3/s]: the natural gas used for other purposes than central heating\n",
    "    delta_Q_int_gas_noCH [J/s]: natural gas used for central heating\n",
    "\n",
    "    delta_Q_int_occup [W]: internal heat gain from occupants\n",
    "    delta_Q_int_occup [W] = Np * Q_int_person_avg [W]\n",
    "    Np [-]: number of persons in the household living in the home\n",
    "    Q_int_person_avg [W]: internal heat gain from persons\n",
    "    \"\"\"\n",
    "    h_E = m.Param(value=60 * 60 * 1000)  # [J/kWh\"], the conversion factor [kWh] to [J]\n",
    "    h_sup = m.Param(value=35170000.0)  # [J/Nm^3] \"superior calorific value of natural gas from the Groningen field\"\n",
    "    eta_hs_noCH = m.Param(value=0.34)  # eq48. and PowerPoint Slide 24 (Effective upper home for indirect heating eff.)\n",
    "\n",
    "    eta_hs_CH = m.Param(value=0.9)\n",
    "    COP_CH = m.Param(value=4)\n",
    "    A_eff = m.Param(value=6)\n",
    "\n",
    "    delta_G_noCH = m.Param(value=339.0 / (365.25 * 24 * 60 * 60))  # [Nm^3/s]\n",
    "    delta_Q_int_gas_noCH = m.Param(value=delta_G_noCH * eta_hs_noCH * h_sup)  # [W]=[J/s]\n",
    "\n",
    "    Np = m.Param(value=2.2)  # average number of people in Dutch household\n",
    "    Q_int_person_avg = m.Param(value=61)  # [J/s] average heat gain for each average person with average behaviour\n",
    "    delta_Q_int_occup = m.Param(value=Np * Q_int_person_avg)  # [J/s]\n",
    "\n",
    "    \"\"\"\"\n",
    "    Manipulated parameter:\n",
    "    delta_Q_int_e [J/s]: internal heat gain from internally used electricity\n",
    "    delta_Q_int_e [J/s] = delta_E_int [kWh/s] * hE [J/kWh]\n",
    "    T_out_eff [K]: effective outdoor temperature\n",
    "    delta_E_CH [kWh]: Electricity used for heat pump\n",
    "    delta_G [Nm3/s] = Natural gas supplied to the home via the natural gas net\n",
    "    I_geo_eff [W/m^2] = geospatially interpolated global horizontal irradiation\n",
    "    \"\"\"\n",
    "    delta_Q_int_e = m.MV(value=delta_Q_int_e_val); delta_Q_int_e.STATUS = 0; delta_Q_int_e.FSTATUS = 1  # [J/s]\n",
    "    T_out_eff = m.MV(value=T_out_eff_arr); T_out_eff.STATUS = 0;T_out_eff.FSTATUS = 1  # [K]\n",
    "    delta_E_CH = m.MV(value=delta_E_CH_val / delta_t); delta_E_CH.STATUS = 0; delta_E_CH.FSTATUS = 1  # [kWh/s]\n",
    "    delta_G = m.MV(value=gas_total / delta_t); delta_G.STATUS = 0; delta_G.FSTATUS = 1  # [Nm^3/s]\n",
    "    I_geo_eff = m.MV(value=I_geo_eff_val / (60*60)); I_geo_eff.STATUS = 0; I_geo_eff.FSTATUS = 1\n",
    "\n",
    "    \"\"\"\"\n",
    "    Control variable:\n",
    "    T_in_sim [K]: Indoor temperature\n",
    "    \"\"\"\n",
    "    T_in_sim = m.CV(value=T_in_meas);\n",
    "    T_in_sim.STATUS = 1;\n",
    "    T_in_sim.FSTATUS = 1;  # T_in_sim.MEAS_GAP= 0.25\n",
    "\n",
    "    ########################################################################################################################\n",
    "    #                                               Gekko - Equations\n",
    "    ########################################################################################################################\n",
    "    \"\"\"\n",
    "    delta_Q_gain [J/s]= delta_Q_CH [J/s] + delta_Q_int [J/s] + delta_Q_sol [J/s]\n",
    "    delta_Q_gain [J/s]= Heat gain\n",
    "    delta_Q_CH [J/s]= Heat gain from central hearting\n",
    "    delta_Q_int [J/s]= Heat gain from internal devices\n",
    "    delta_Q_sol [J/s]= delta_Q_int from solar irradiation\n",
    "    \"\"\"\n",
    "\n",
    "    ########################################################################################################################\n",
    "    #                                               Equation - delta_Q_CH\n",
    "    ########################################################################################################################\n",
    "    \"\"\"\"\n",
    "    delta_Q_CH [J/s] = (delta_G_CH [Nm3/s] * eta_hs_ch [-] * h_sup [J/Nm3]) + (delta_E_CH [kWh/s] * COP_CH [-] * hE [J/kWh])\n",
    "    delta_G_CH [Nm3/s] = Natural gas used for central heating\n",
    "    delta_G_CH [Nm3/s] = delta_G [Nm3/s]- delta_G_noCH [Nm3/s]\n",
    "    \"\"\"\n",
    "\n",
    "    delta_G_CH = m.Intermediate(delta_G - delta_G_noCH)  # [Nm3/s]\n",
    "    delta_Q_CH = m.Intermediate((delta_G_CH * eta_hs_CH * h_sup) + (delta_E_CH * COP_CH * h_E))  # [J/s]\n",
    "    # delta_Q_CH = m.Intermediate((delta_Q_CH * eta_hs_CH * h_sup) + (delta_E_CH * COP_CH * h_E))  # [J/s]\n",
    "    ########################################################################################################################\n",
    "    #                                                   Equation - delta_Q_int\n",
    "    ########################################################################################################################\n",
    "    \"\"\"\"\n",
    "    delta_Q_int [J/s]: total internal heat\n",
    "    delta_Q_int [J/s]= delta_Q_int_e + delta_Q_int_occup + delta_Q_int_gas_noCH\n",
    "    delta_E_int [kWh/s] = delta_E_supply [kWh/s] + delta_E_PV [kWh/s] - delta_E_ret [kWh/s] - delta_E_EVcharge [kWh/s]\n",
    "    \"\"\"\n",
    "    delta_Q_int = m.Intermediate(delta_Q_int_e + delta_Q_int_occup + delta_Q_int_gas_noCH)  # [J/s]\n",
    "\n",
    "    ########################################################################################################################\n",
    "    #                                                   Equation - delta_Q_sol\n",
    "    ########################################################################################################################\n",
    "    delta_Q_sol = m.Intermediate(A_eff * I_geo_eff)  # [J/s]\n",
    "\n",
    "    ########################################################################################################################\n",
    "    #                                                    Equation - delta_Q_gain\n",
    "    ########################################################################################################################\n",
    "    delta_Q_gain = m.Intermediate(delta_Q_CH + delta_Q_sol + delta_Q_int)  # [J/s]\n",
    "\n",
    "    ########################################################################################################################\n",
    "    #                                                   Final Equations\n",
    "    ########################################################################################################################\n",
    "    C_eff = m.Intermediate(H * tau)\n",
    "    m.Equation(T_in_sim.dt() == (delta_Q_gain - (H * (T_in_sim - T_out_eff))) / C_eff)\n",
    "\n",
    "    ########################################################################################################################\n",
    "    #                                                    Solve Equations\n",
    "    ########################################################################################################################\n",
    "    m.options.IMODE = 5\n",
    "    m.options.EV_TYPE = 1  # specific objective function (L1-norm vs L2-norm)\n",
    "    m.options.NODES = 2\n",
    "    # m.options.CV_TYPE = 2\n",
    "    # add dead-band for measurement to avoid overfitting\n",
    "    # T_in_sim.MEAS_GAP = 0.25\n",
    "    m.solve(disp=False)\n",
    "\n",
    "    ########################################################################################################################\n",
    "    #                                                       Result\n",
    "    ########################################################################################################################\n",
    "    print(\n",
    "        \"Start point: {} ====> End point: {}\".format(df.loc[start_point, 'Date_Time'], df.loc[end_point, 'Date_Time']))\n",
    "    print('Iter: ', j)\n",
    "    print('effective thermal inertia: tau [hr]: ' + str(round(tau.value[0] / 3600, 2)))\n",
    "    # print('upper heating efficiency of the central heating system: eta_hs [-]: ' + str(round(eta_hs_CH.value[0], 2)))\n",
    "    # print('Coef. of Performance for heat pump: COP_CH [-]: ' + str(round(COP_CH.value[0], 2)))\n",
    "    print('specific heat loss: H [W/K]: ' + str(round(H.value[0], 2)))\n",
    "    print('Effective area of solar aperture in the horizontal plane: A_eff [m^2]: ' + str(round(A_eff.value[0], 2)))\n",
    "    print('*' * 50)\n",
    "\n",
    "    row_num = printing_row + j\n",
    "    wb = openpyxl.load_workbook(filename='result.xlsx')\n",
    "    ws = wb.worksheets[0]\n",
    "    ws.cell(row=row_num, column=2).value = pseudonym\n",
    "    ws.cell(row=row_num, column=3).value = df['Date_Time'][start_point]\n",
    "    ws.cell(row=row_num, column=4).value = df['Date_Time'][end_point]\n",
    "    ws.cell(row=row_num, column=5).value = duration\n",
    "    ws.cell(row=row_num, column=6).value = round(tau.value[0] / 3600, 2)\n",
    "    ws.cell(row=row_num, column=7).value = round(H.value[0], 2)\n",
    "    ws.cell(row=row_num, column=8).value = A_eff.value[0]\n",
    "    ws.cell(row=row_num, column=9).value = COP_CH.value[0]\n",
    "    ws.cell(row=row_num, column=10).value = round(eta_hs_CH.value[0], 2)\n",
    "    \n",
    "    wb.save(\"result.xlsx\")\n",
    "\n",
    "\n",
    "    result_dict = {'pseudonym': pseudonym, \n",
    "                   'start_point': df.loc[start_point, 'Date_Time'],\n",
    "                   'end_point': df.loc[end_point, 'Date_Time'],\n",
    "                   'duration [days]': duration,\n",
    "                   'tau [h]': round(tau.value[0] / 3600, 2), \n",
    "                   'H [W/K]': round(H.value[0], 2),\n",
    "                   'A_eff [m^2]': A_eff.value[0], \n",
    "                   'COP_CH': COP_CH.value[0], \n",
    "                   'eta_hs_CH': eta_hs_CH.value[0]\n",
    "                  }\n",
    "    \n",
    "    result_per_home_df = result_per_home_df.append(result_dict, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35348cb5-8db8-4951-899e-d906dc88c1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as plt\n",
    "\n",
    "plt.figure()\n",
    "result_per_home_df['tau [h]'].plot(x='start_point')\n",
    "plt.xlabel('Date and Time')\n",
    "plt.ylabel('Hour')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ff942f-fda5-4e49-a9e9-ff2f91228008",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "result_per_home_df['H [W/K]'].plot()\n",
    "plt.xlabel('Date and Time')\n",
    "plt.ylabel('H [W/K]')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57d8aba-45a9-4022-9445-1bfce9bcf078",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_result_df = total_result_df.append(result_per_home_df, ignore_index = True)\n",
    "total_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09db9a93-faab-4d58-a88a-9dcb9a178afb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
