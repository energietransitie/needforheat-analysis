{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52649ab-50eb-4157-bb37-3c1889197851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "import pylab as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# usually, two decimals suffice for displaying DataFrames (NB internally, precision may be higher)\n",
    "pd.options.display.precision = 2\n",
    "import sys\n",
    "sys.path.append('../data/')\n",
    "\n",
    "%load_ext autoreload\n",
    "import gc\n",
    "\n",
    "from measurements import Measurements\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Replace 'file_path' with the actual path to your file\n",
    "file_path='remeha_schedules_20231129-20240402.parquet'\n",
    "file_output_path='remeha_schedules_export.parquet'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389baf3f-edce-497e-9adb-92fc1634b5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the file size in bytes\n",
    "file_size_bytes = os.path.getsize(file_path)\n",
    "\n",
    "# Convert file size to kilobytes, megabytes, etc. for better readability\n",
    "file_size_kb = file_size_bytes / 1024\n",
    "file_size_mb = file_size_kb / 1024\n",
    "file_size_gb = file_size_mb / 1024\n",
    "\n",
    "# Print the file size\n",
    "print(f\"File Size: {file_size_bytes} bytes ({file_size_kb:.2f} KB, {file_size_mb:.2f} MB, {file_size_gb:.2f} GB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5015bcd1-4d79-4ffc-aebc-1ac378c29a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Attempt to read the Parquet file\n",
    "try:\n",
    "    df_schedules = pd.read_parquet(\n",
    "        file_path, \n",
    "        engine='pyarrow',\n",
    "        dtype_backend='numpy_nullable'\n",
    "        )\n",
    "    print(\"File was successfully read without specifying compression codec.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error reading file: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d332e66-67ed-49ff-811b-55195bbcea62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_schedules.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68115290-b829-43a9-9fed-c7763672ef0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_schedules.memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29918bf6-5141-471a-a5af-1745d64534d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the 'pseudonym' column to 'id' and set as index\n",
    "df_schedules.rename(columns={'pseudonym': 'id'}, inplace=True)\n",
    "df_schedules = df_schedules.set_index(['id', 'zone_type', 'zone_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cfde72-356d-4ec9-b025-a2e87a95f8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(df_schedules.index.get_level_values('id').unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75062f3e-fb0a-4643-baa6-5595b7f79144",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_schedules.index.get_level_values('zone_type').unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb29557-f55f-4048-926b-9834ffd97fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_schedules.reset_index()[['zone_type', 'zone_name']].drop_duplicates().values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0116a2-510a-4a0e-8741-dfaaa1fb2555",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_schedules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f16432-7290-4aff-bf86-e07f9e6eaa25",
   "metadata": {},
   "source": [
    "## Delete duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2b0667-11eb-4a04-964f-7b49f7a04fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_schedules = df_schedules.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9932c1-cb64-4540-b496-97b8cecaeb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_schedules.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3210f389-2eb3-4f18-b003-c3c0df4c0427",
   "metadata": {},
   "source": [
    "## Select only CH schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667daca1-a820-4afc-b4c6-cf8979005594",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice\n",
    "df_ch_schedules = df_schedules.loc[idx[:,'CH',:],['heating_program', 'heating_activities', 'valid_from','valid_to']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dffb07-0490-438d-be91-ccd37a43bf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ch_schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6364be78-1e02-4a93-abf1-1660ff2d8eef",
   "metadata": {},
   "outputs": [],
   "source": [
    " df_ch_schedules.groupby(['id', 'zone_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b03b51-4704-4e22-b10c-5f1e7d3687a9",
   "metadata": {},
   "outputs": [],
   "source": [
    " df_ch_schedules.groupby(['id', 'zone_type', 'zone_name']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca93f271-3ef7-4e02-8a14-a6859b43d06e",
   "metadata": {},
   "source": [
    "## Select only analyzed ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be19f87-8f3b-458f-9f94-c5d229cdc736",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_ids = [401632,\n",
    " 403603,\n",
    " 404873,\n",
    " 410260,\n",
    " 412715,\n",
    " 424197,\n",
    " 429011,\n",
    " 430062,\n",
    " 434931,\n",
    " 444964,\n",
    " 449134,\n",
    " 450298,\n",
    " 456638,\n",
    " 458000,\n",
    " 458852,\n",
    " 478667,\n",
    " 483173,\n",
    " 487126,\n",
    " 494233,\n",
    " 495906]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cded69-87ba-4ac1-be3c-e6d2bc6d87f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ch_schedules_analysis = df_ch_schedules.loc[df_ch_schedules.index.get_level_values('id').isin(analysis_ids)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e389f0-7f2b-41ff-aa57-ae536a20c064",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ch_schedules_analysis.groupby(['id', 'zone_type', 'zone_name']).count().sort_values(by='heating_program', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4a5ef4-d10a-438a-a6ba-d1543d6fa767",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ch_schedules_analysis.groupby(['id', 'zone_type', 'zone_name']).count().sort_values(by='heating_program', ascending=True).to_excel('count_schedules.xlsx', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b41eda-e127-4e28-9ca2-091854f0901a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepdiff import DeepDiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbbbc46-3ef2-4680-9677-d376c23511c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to compare rows\n",
    "def compare_rows(row1, row2):\n",
    "    return DeepDiff(json.loads(row1['heating_program']), json.loads(row2['heating_program'])), DeepDiff(json.loads(row1['heating_activities']), json.loads(row2['heating_activities']))\n",
    "# Function to compare rows safely\n",
    "def compare_rows(row1, row2):\n",
    "    # Convert to JSON if not None\n",
    "    heating_program1 = json.loads(row1['heating_program']) if pd.notna(row1['heating_program']) else None\n",
    "    heating_program2 = json.loads(row2['heating_program']) if pd.notna(row2['heating_program']) else None\n",
    "    \n",
    "    heating_activities1 = json.loads(row1['heating_activities']) if pd.notna(row1['heating_activities']) else None\n",
    "    heating_activities2 = json.loads(row2['heating_activities']) if pd.notna(row2['heating_activities']) else None\n",
    "    \n",
    "    return DeepDiff(heating_program1, heating_program2), DeepDiff(heating_activities1, heating_activities2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f594a7-e1e3-4faf-96f1-bbb2da0b421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for differences in consecutive rows that have the same valid_from\n",
    "for id in analysis_ids:\n",
    "     df_filtered = df_ch_schedules.loc[df_ch_schedules.index.get_level_values('id')==id]\n",
    "     # Iterate over the DataFrame to find differences\n",
    "     for i in range(1, len(df_filtered)):\n",
    "         row1 = df_filtered.iloc[i - 1]\n",
    "         row2 = df_filtered.iloc[i]\n",
    "         # Check if 'valid_from' and 'valid_to' are equal\n",
    "         if row1['valid_from'] == row2['valid_from'] and row1['valid_to'] == row2['valid_to']:\n",
    "             diff_program, diff_activities = compare_rows(row1, row2)\n",
    "             if diff_program or diff_activities:\n",
    "                 print(f\"\\nDifferences for id {id} between row {i-1} and row {i}, both valid from {row1['valid_from']} to {row1['valid_to']}:\")\n",
    "                 print(\"- Heating Program Diff:\", diff_program)\n",
    "                 print(\"- Heating Activities Diff:\", diff_activities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d315c2-1f86-4e24-991c-a326c52e0093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for differences in consecutive rows that do NOT have the same valid_from\n",
    "for id in analysis_ids:\n",
    "     df_filtered = df_ch_schedules.loc[df_ch_schedules.index.get_level_values('id')==id]\n",
    "     # Iterate over the DataFrame to find differences\n",
    "     for i in range(1, len(df_filtered)):\n",
    "         row1 = df_filtered.iloc[i - 1]\n",
    "         row2 = df_filtered.iloc[i]\n",
    "         # Check if 'valid_from' and 'valid_to' are equal\n",
    "         if row1['valid_from'] != row2['valid_from'] and row1['valid_to'] != row2['valid_to']:\n",
    "             diff_program, diff_activities = compare_rows(row1, row2)\n",
    "             if diff_program or diff_activities:\n",
    "                 print(f\"\\nDifferences for id {id} between row valid from {row1['valid_from']} to {row1['valid_to']} and {row2['valid_from']} to {row2['valid_to']}:\")\n",
    "                 print(\"- Heating Program Diff:\", diff_program)\n",
    "                 print(\"- Heating Activities Diff:\", diff_activities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7e03cb-ce29-49cc-9fb9-2567c659eb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    " for id in analysis_ids:\n",
    "     display(df_ch_schedules.drop_duplicates().loc[df_ch_schedules.drop_duplicates().index.get_level_values('id')==id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3749785-33df-42e0-a776-8a44413a5780",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(df_ch_schedules_analysis.index.get_level_values('zone_name').unique().to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9994489d-6b51-4eb8-914d-05c6312c656c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in analysis_ids:\n",
    "    heating_program = df_ch_schedules_analysis.loc[(id, 'CH'),'heating_program']\n",
    "    # Convert JSON string to dictionary and print it\n",
    "    for zone, program in heating_program.items():\n",
    "        print(f\"\\nID: {id}, ZONE: {zone}, PROGRAM: {json.loads(program)}\")\n",
    "\n",
    "    heating_activities = df_ch_schedules_analysis.loc[(id, 'CH'),'heating_activities']\n",
    "    # Convert JSON string to dictionary and print it\n",
    "    for zone, activities in heating_activities.items():\n",
    "        print(f\"\\nID: {id}, ZONE: {zone}, ACTIVITIES: {json.loads(activities)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21662b4d-fa47-4567-b96e-98ce98656260",
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in analysis_ids:\n",
    "     # Sample heating_activities and heating_program data\n",
    "    for zone, program in heating_program.items():\n",
    "        heating_program = json.loads(df_ch_schedules_analysis.loc[(id, 'CH'), 'heating_program'][zone])\n",
    "        heating_activities = json.loads(df_ch_schedules_analysis.loc[(id, 'CH'), 'heating_activities'][zone])\n",
    "        \n",
    "        # Create a dictionary to map ActivityNumber to temperature from heating_activities\n",
    "        activity_temps = {activity['ActivityNumber']: activity['Temperature'] for activity in heating_activities}\n",
    "        \n",
    "        # Variable to track if all temperatures are consistent\n",
    "        all_consistent = True\n",
    "        \n",
    "        # Iterate through the heating program and compare temperatures\n",
    "        for program_name, days in heating_program.items():\n",
    "            # Check if the value for program_name is a dictionary (expected structure), skip if it's not\n",
    "            if isinstance(days, dict):\n",
    "                for day, entries in days.items():\n",
    "                    for entry in entries:\n",
    "                        activity_num = entry['ActivityNumber']\n",
    "                        program_temp = entry.get('Temperature')  # Get the temperature in the heating_program\n",
    "                        activity_temp = activity_temps.get(activity_num)  # Get the corresponding temperature from heating_activities\n",
    "        \n",
    "                        # Check for consistency\n",
    "                        if program_temp is not None and activity_temp is not None:\n",
    "                            if program_temp != activity_temp:\n",
    "                                print(f\"Inconsistency on {day} for {program_name} at {entry['StartTime']}: \"\n",
    "                                      f\"Program temperature is {program_temp}, but activity temperature is {activity_temp}.\")\n",
    "                                all_consistent = False\n",
    "                            else:\n",
    "                                print(f\"Consistent on {day} for {program_name} at {entry['StartTime']}: \"\n",
    "                                      f\"Temperature is {program_temp}.\")\n",
    "            else:\n",
    "                print(f\"Skipping {program_name}: value is not a dictionary, but {type(days)}\")\n",
    "        \n",
    "        # Print a message confirming if all temperatures were consistent\n",
    "        if all_consistent:\n",
    "            print(f\"All temperatures in the heating program  for id {id} and zone {zone} are consistent with the activity temperatures.\")\n",
    "        else:\n",
    "            print(f\"There were inconsistencies found in the heating program for id {id} and zone {zone}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935f08e7-e6af-472a-8e9a-20839ef64c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "df.to_parquet(file_output_path, index=True, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f09fed-bb96-490f-b2ef-a9b952858e26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
