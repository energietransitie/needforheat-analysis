{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4c00144-2555-4b0e-b82e-7d7603c3fc63",
   "metadata": {},
   "source": [
    "# Preprocess schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52649ab-50eb-4157-bb37-3c1889197851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "import pylab as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import difflib\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# usually, two decimals suffice for displaying DataFrames (NB internally, precision may be higher)\n",
    "pd.options.display.precision = 2\n",
    "import sys\n",
    "sys.path.append('../data/')\n",
    "\n",
    "%load_ext autoreload\n",
    "import gc\n",
    "\n",
    "from measurements import Measurements\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Replace 'file_path' with the actual path to your file\n",
    "file_path='remeha_schedules_20231129-20240402.parquet'\n",
    "file_output_path='remeha_schedules_export.parquet'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf683f6-3053-4506-b10c-6948d58a25ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_schedule_info(heating_program_json):\n",
    "    \"\"\"\n",
    "    Extract the day of the week, start time (local time), and temperature setpoint\n",
    "    from the heating program.\n",
    "    \"\"\"\n",
    "    heating_program = json.loads(heating_program_json)\n",
    "    \n",
    "    # Assuming the heating program contains only one zone (as per your requirements)\n",
    "    if len(heating_program) > 1:\n",
    "        raise Exception(\"Multiple zones found in heating program.\")\n",
    "    \n",
    "    schedule_data = []\n",
    "    \n",
    "    # Loop over days of the week (assuming structure like {\"HeatingProgram1\": {day: [...], day: [...]}})\n",
    "    for day, events in heating_program['HeatingProgram1'].items():\n",
    "        for event in events:\n",
    "            start_time_str = event['StartTime']  # Example: \"07:00\"\n",
    "            setpoint = event['SetPoint'] if 'SetPoint' in event else event['Temperature']\n",
    "            \n",
    "            # Convert start time to datetime object (assumes the time is in HH:MM format)\n",
    "            start_time = datetime.strptime(start_time_str, '%H:%M').time()\n",
    "            \n",
    "            # Collect day of week, start time, and temperature setpoint\n",
    "            schedule_data.append({\n",
    "                'day_of_week': day,\n",
    "                'start_time': start_time,\n",
    "                'setpoint': setpoint\n",
    "            })\n",
    "    \n",
    "    return schedule_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1d4334-5055-4e93-8ecd-11a0419f6a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get ISO weekday number\n",
    "def iso_weekday(day):\n",
    "    weekdays = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    return weekdays.index(day)\n",
    "\n",
    "def parse_heating_program(heating_program_json, heating_activities_json):\n",
    "    # Parse the input JSON strings\n",
    "    heating_programs = json.loads(heating_program_json)\n",
    "    heating_activities = json.loads(heating_activities_json)\n",
    "    \n",
    "    # Get the active time program number\n",
    "    active_program_number = heating_programs.get(\"ActiveTimeProgram\")\n",
    "    \n",
    "    if not active_program_number:\n",
    "        return []  # Return an empty list if no active program is found\n",
    "\n",
    "    # Convert the active program number to the corresponding key\n",
    "    active_program_key = f\"HeatingProgram{active_program_number}\"\n",
    "    \n",
    "    # Get the active heating program schedule\n",
    "    active_schedule = heating_programs.get(active_program_key, {})\n",
    "\n",
    "    # Use a dictionary to store unique day/time entries with temperature\n",
    "    schedule_dict = defaultdict(dict)\n",
    "    \n",
    "    # Loop over each day's schedule in the active program\n",
    "    for day, activities in active_schedule.items():\n",
    "        for activity in activities:\n",
    "            start_time = activity.get('StartTime')\n",
    "            activity_number = activity.get('ActivityNumber')\n",
    "\n",
    "            # Initialize temperature\n",
    "            temperature = None\n",
    "            \n",
    "            # If ActivityNumber exists, find the corresponding activity by ActivityNumber\n",
    "            if activity_number is not None:\n",
    "                matching_activity = next((a for a in heating_activities if a['ActivityNumber'] == activity_number), None)\n",
    "\n",
    "                # If a matching activity is found, use its temperature\n",
    "                if matching_activity:\n",
    "                    temperature = matching_activity.get('Temperature')\n",
    "            \n",
    "            # Use Temperature from activity if it exists and no matching activity was found\n",
    "            if temperature is None:\n",
    "                temperature = activity.get('Temperature')\n",
    "            \n",
    "            # If there's a temperature value (from ActivityNumber or direct temperature), add to schedule\n",
    "            if temperature is not None and start_time is not None:\n",
    "                # Check for duplicates or conflicts\n",
    "                if start_time in schedule_dict[day]:\n",
    "                    if schedule_dict[day][start_time] != temperature:\n",
    "                        raise ValueError(f\"Conflicting temperatures for {day} at {start_time}: {schedule_dict[day][start_time]} vs {temperature}\")\n",
    "                else:\n",
    "                    schedule_dict[day][start_time] = temperature\n",
    "\n",
    "    # Sort the schedule by ISO weekday order and start time\n",
    "    result = []\n",
    "    for day in sorted(schedule_dict.keys(), key=iso_weekday):\n",
    "        for start_time in sorted(schedule_dict[day].keys()):\n",
    "            result.append({\n",
    "                'day': day,\n",
    "                'start_time': start_time,\n",
    "                'temperature': schedule_dict[day][start_time]\n",
    "            })\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70654f9-e3e0-4350-8a85-680ee962ce57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate HTML diff between two lists of dictionaries\n",
    "def generate_diff(previous, current):\n",
    "    \"\"\"Generate an HTML diff between two lists of dictionaries.\"\"\"\n",
    "    # Convert lists of dictionaries to JSON strings\n",
    "    previous_json = json.dumps(previous, indent=4) if previous else ''\n",
    "    current_json = json.dumps(current, indent=4) if current else ''\n",
    "\n",
    "    if previous_json == '':  # If there is no previous program\n",
    "        return f\"<span style='color: green;'>New: {current_json}</span>\"\n",
    "    elif current_json == '':  # If there is no current program\n",
    "        return f\"<span style='color: red;'>Removed: {previous_json}</span>\"\n",
    "\n",
    "    # Generate diff using difflib\n",
    "    diff = difflib.ndiff(previous_json.splitlines(), current_json.splitlines())\n",
    "    html_diff = []\n",
    "\n",
    "    for line in diff:\n",
    "        line = line.strip()  # Remove leading/trailing whitespace\n",
    "        if line.startswith('+ '):\n",
    "            html_diff.append(f\"<span style='color: green;'>{line[2:]}</span>\")  # Added lines in green\n",
    "        elif line.startswith('- '):\n",
    "            html_diff.append(f\"<span style='color: red; text-decoration: line-through;'>{line[2:]}</span>\")  # Removed lines in red\n",
    "        elif line.startswith('^'):  # Ignore lines starting with ^\n",
    "            continue\n",
    "        else:\n",
    "            html_diff.append(line[2:])  # Unchanged lines\n",
    "\n",
    "    return ''.join(html_diff)  # Join without breaks for HTML display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e7fe56-5218-4d03-86dd-ba4d4458aeb2",
   "metadata": {},
   "source": [
    "## Read schedule file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389baf3f-edce-497e-9adb-92fc1634b5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the file size in bytes\n",
    "file_size_bytes = os.path.getsize(file_path)\n",
    "\n",
    "# Convert file size to kilobytes, megabytes, etc. for better readability\n",
    "file_size_kb = file_size_bytes / 1024\n",
    "file_size_mb = file_size_kb / 1024\n",
    "file_size_gb = file_size_mb / 1024\n",
    "\n",
    "# Print the file size\n",
    "print(f\"File Size: {file_size_bytes} bytes ({file_size_kb:.2f} KB, {file_size_mb:.2f} MB, {file_size_gb:.2f} GB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5015bcd1-4d79-4ffc-aebc-1ac378c29a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Attempt to read the Parquet file\n",
    "try:\n",
    "    df_schedules = pd.read_parquet(\n",
    "        file_path, \n",
    "        engine='pyarrow',\n",
    "        dtype_backend='numpy_nullable'\n",
    "        )\n",
    "    print(\"File was successfully read without specifying compression codec.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error reading file: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d332e66-67ed-49ff-811b-55195bbcea62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_schedules.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68115290-b829-43a9-9fed-c7763672ef0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_schedules.memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29918bf6-5141-471a-a5af-1745d64534d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the 'pseudonym' column to 'id' and set as index\n",
    "df_schedules.rename(columns={'pseudonym': 'id'}, inplace=True)\n",
    "df_schedules = df_schedules.set_index(['id', 'zone_type', 'zone_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cfde72-356d-4ec9-b025-a2e87a95f8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(df_schedules.index.get_level_values('id').unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75062f3e-fb0a-4643-baa6-5595b7f79144",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_schedules.index.get_level_values('zone_type').unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb29557-f55f-4048-926b-9834ffd97fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_schedules.reset_index()[['zone_type', 'zone_name']].drop_duplicates().values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f16432-7290-4aff-bf86-e07f9e6eaa25",
   "metadata": {},
   "source": [
    "## Delete duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2b0667-11eb-4a04-964f-7b49f7a04fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_count = df_schedules.shape[0]  # Count before deletion\n",
    "df_schedules = df_schedules.drop_duplicates()\n",
    "deleted_count = initial_count - df_schedules.shape[0]  # Count deleted rows\n",
    "display(deleted_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9932c1-cb64-4540-b496-97b8cecaeb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_schedules.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3210f389-2eb3-4f18-b003-c3c0df4c0427",
   "metadata": {},
   "source": [
    "## Select only CH schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667daca1-a820-4afc-b4c6-cf8979005594",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice\n",
    "df_ch_schedules = df_schedules.loc[idx[:,'CH',:],['heating_program', 'heating_activities', 'valid_from','valid_to']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dffb07-0490-438d-be91-ccd37a43bf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ch_schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6364be78-1e02-4a93-abf1-1660ff2d8eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ch_schedules.groupby(['id', 'zone_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b03b51-4704-4e22-b10c-5f1e7d3687a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ch_schedules.groupby(['id', 'zone_type', 'zone_name']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca93f271-3ef7-4e02-8a14-a6859b43d06e",
   "metadata": {},
   "source": [
    "## Select only analyzed ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be19f87-8f3b-458f-9f94-c5d229cdc736",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_ids = [401632,\n",
    " 403603,\n",
    " 404873,\n",
    " 410260,\n",
    " 412715,\n",
    " 424197,\n",
    " 429011,\n",
    " 430062,\n",
    " 434931,\n",
    " 444964,\n",
    " 449134,\n",
    " 450298,\n",
    " 456638,\n",
    " 458000,\n",
    " 458852,\n",
    " 478667,\n",
    " 483173,\n",
    " 487126,\n",
    " 494233,\n",
    " 495906]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cded69-87ba-4ac1-be3c-e6d2bc6d87f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ch_schedules_analysis = df_ch_schedules.loc[df_ch_schedules.index.get_level_values('id').isin(analysis_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc17568-22c3-455c-8ac6-d0d062820b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_intervals = df_ch_schedules_analysis[df_ch_schedules_analysis['valid_from'] > df_ch_schedules_analysis['valid_to']]\n",
    "if not invalid_intervals.empty:\n",
    "    print(\"Invalid intervals found:\")\n",
    "    with pd.option_context('display.max_colwidth', None):\n",
    "        display(invalid_intervals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e389f0-7f2b-41ff-aa57-ae536a20c064",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ch_schedules_analysis.groupby(['id', 'zone_type', 'zone_name']).count().sort_values(by='heating_program', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e820874e-9bf4-4ec2-a0ce-3e11c4e5fe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the new parsing logic that uses heating_activities if temperature is not embedded\n",
    "df_ch_schedules_analysis.loc[:,'active_schedule'] = df_ch_schedules_analysis.apply(\n",
    "    lambda row: parse_heating_program(row['heating_program'], row['heating_activities']) if pd.notna(row['heating_program']) and pd.notna(row['heating_activities']) else None, axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2ce6d8-7a16-4f4e-95ea-ae6e32e8de17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3:  Ensure valid_from and valid_to are both datetime\n",
    "df_ch_schedules_analysis.loc[:,'valid_from'] = pd.to_datetime(df_ch_schedules_analysis['valid_from'])\n",
    "df_ch_schedules_analysis.loc[:,'valid_to'] = pd.to_datetime(df_ch_schedules_analysis['valid_to'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b512c2b9-8194-444d-b278-ddba20b05ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Fill NaT in valid_to with valid_from of the next row within the same id\n",
    "# Resetting index to simplify access\n",
    "df_ch_schedules_analysis = df_ch_schedules_analysis.reset_index().sort_values(by=['id', 'valid_from'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12cf44d-6620-42e1-9d95-4ed9fad18cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_ch_schedules_analysis) - 1):\n",
    "    current_row = df_ch_schedules_analysis.iloc[i]\n",
    "    next_row = df_ch_schedules_analysis.iloc[i + 1]\n",
    "    \n",
    "    # Check if the current row has a NaT valid_to and the next row has the same id\n",
    "    if pd.isna(current_row['valid_to']) and current_row['id'] == next_row['id']:\n",
    "        # Fill NaT with the valid_from of the next row\n",
    "        df_ch_schedules_analysis.at[current_row.name, 'valid_to'] = next_row['valid_from']\n",
    "        print(f\"Filled NaT with the valid_from of the next row: {next_row['valid_from']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c68207-770d-4e82-8eb5-4cf23c825c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: fill NaT with future date\n",
    "df_ch_schedules_analysis.loc[:,'valid_to'] = df_ch_schedules_analysis['valid_to'].fillna(pd.Timestamp('2100-12-31').tz_localize('Europe/Amsterdam'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b0807e-a931-4152-8f0f-7d3768df1232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Create IntervalIndex using valid_from and valid_to\n",
    "df_ch_schedules_analysis.loc[:,'valid_interval'] = pd.IntervalIndex.from_arrays(\n",
    "    df_ch_schedules_analysis['valid_from'].values,  # Ensure it's an array\n",
    "    df_ch_schedules_analysis['valid_to'].values    # Ensure it's an array\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f886ca4-6088-415f-9162-8602772ceb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Create a copy with specified MultiIndex and columns\n",
    "df_ch_schedules_analysis = df_ch_schedules_analysis.copy().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8d53c5-3f82-4992-a484-04d3814202d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now set the MultiIndex [id, valid_interval]\n",
    "df_ch_schedules_analysis.set_index(['id', 'valid_interval'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f9d123-afe1-480b-8949-f0d4ddf62af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only 'zone_name' and 'active_schedule' (renamed to 'program')\n",
    "df_ch_schedules_analysis = df_ch_schedules_analysis[['zone_name', 'active_schedule']].rename(columns={'active_schedule': 'program'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092f6737-997a-4dfb-95d1-a6ef2d760e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Remove duplicates\n",
    "initial_count = df_ch_schedules_analysis.shape[0]  # Count before deletion\n",
    "df_ch_schedules_analysis = df_ch_schedules_analysis[~df_ch_schedules_analysis.index.duplicated(keep='first')]  # Keep the first occurrence of duplicates\n",
    "deleted_count = initial_count - df_ch_schedules_analysis.shape[0]  # Count deleted rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ac8cff-fbd5-4b3e-aa90-9ae94e6e6fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "deleted_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e81c96-4ad7-4e4e-8500-534399a60d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ch_schedules_analysis = df_ch_schedules_analysis.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2209db0e-a378-4caf-a304-eb65fa4af46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ch_schedules_analysis = df_ch_schedules_analysis.drop(columns='zone_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac8d4a6-bc33-4cd0-a582-ea57e9e04fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_colwidth', None):\n",
    "    display(df_ch_schedules_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4d888f-9048-48d5-8415-f27bcb1c88fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare to hold the generated HTML diff\n",
    "df_ch_schedules_analysis['previous_program'] = None\n",
    "df_ch_schedules_analysis['diff'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa35632-a650-452a-a675-bb24acdd6662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the DataFrame\n",
    "for i in range(1, len(df_ch_schedules_analysis)):\n",
    "    current_row = df_ch_schedules_analysis.iloc[i]\n",
    "    previous_row = df_ch_schedules_analysis.iloc[i - 1]\n",
    "\n",
    "    # Check if the current and previous rows have the same id\n",
    "    if current_row.name[0] == previous_row.name[0]:  # Compare 'id' from MultiIndex\n",
    "        # Generate the HTML diff\n",
    "        previous_program = previous_row['program']\n",
    "        current_program = current_row['program']\n",
    "        \n",
    "        df_ch_schedules_analysis.at[current_row.name, 'previous_program'] = previous_program\n",
    "        df_ch_schedules_analysis.at[current_row.name, 'diff'] = generate_diff(previous_program, current_program)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31181ccf-63f5-4ad1-9afd-1156e2f38a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the DataFrame with HTML rendering\n",
    "with pd.option_context('display.max_colwidth', None):\n",
    "    # Display only the relevant columns with HTML\n",
    "    display(HTML(df_ch_schedules_analysis[['diff']].to_html(escape=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca5144f-c735-45be-922a-f339a4cb6559",
   "metadata": {},
   "source": [
    "## Write schedules to parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8948e2a-ca19-494a-807f-54fdbcc257c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ch_schedules_analysis_to_write = df_ch_schedules_analysis.drop(columns = ['previous_program', 'diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f46e28-713e-439b-9932-79e011264410",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_colwidth', None):\n",
    "    display(df_ch_schedules_analysis_to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935f08e7-e6af-472a-8e9a-20839ef64c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "df_ch_schedules_analysis_to_write.to_parquet(file_output_path, index=True, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f09fed-bb96-490f-b2ef-a9b952858e26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
