{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4c00144-2555-4b0e-b82e-7d7603c3fc63",
   "metadata": {},
   "source": [
    "# Preprocess thermostat programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52649ab-50eb-4157-bb37-3c1889197851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "import pylab as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import sys\n",
    "sys.path.append('../data/')\n",
    "sys.path.append('../view/')\n",
    "sys.path.append('../analysis/')\n",
    "\n",
    "from plotter import Plot\n",
    "\n",
    "import difflib\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# usually, two decimals suffice for displaying DataFrames (NB internally, precision may be higher)\n",
    "pd.options.display.precision = 2\n",
    "\n",
    "%load_ext autoreload\n",
    "import gc\n",
    "\n",
    "from measurements import Measurements\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Replace 'file_path' with the actual path to your file\n",
    "file_path='remeha_schedules_20231129-20240402.parquet'\n",
    "file_output_path='remeha_programs_export.parquet'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1d4334-5055-4e93-8ecd-11a0419f6a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get ISO weekday number\n",
    "def iso_weekday(day):\n",
    "    weekdays = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    return weekdays.index(day)\n",
    "\n",
    "def parse_heating_program(heating_program_json, heating_activities_json):\n",
    "    # Parse the input JSON strings\n",
    "    heating_programs = json.loads(heating_program_json)\n",
    "    heating_activities = json.loads(heating_activities_json)\n",
    "    \n",
    "    # Get the active time program number\n",
    "    active_program_number = heating_programs.get(\"ActiveTimeProgram\")\n",
    "    \n",
    "    if not active_program_number:\n",
    "        return []  # Return an empty list if no active program is found\n",
    "\n",
    "    # Convert the active program number to the corresponding key\n",
    "    active_program_key = f\"HeatingProgram{active_program_number}\"\n",
    "    \n",
    "    # Get the active heating program program\n",
    "    active_program = heating_programs.get(active_program_key, {})\n",
    "\n",
    "    # Use a dictionary to store unique day/time entries with temperature\n",
    "    program_dict = defaultdict(dict)\n",
    "    \n",
    "    # Loop over each day's program in the active program\n",
    "    for day, activities in active_program.items():\n",
    "        for activity in activities:\n",
    "            start_time = activity.get('StartTime')\n",
    "            activity_number = activity.get('ActivityNumber')\n",
    "\n",
    "            # Initialize temperature\n",
    "            temperature = None\n",
    "            \n",
    "            # If ActivityNumber exists, find the corresponding activity by ActivityNumber\n",
    "            if activity_number is not None:\n",
    "                matching_activity = next((a for a in heating_activities if a['ActivityNumber'] == activity_number), None)\n",
    "\n",
    "                # If a matching activity is found, use its temperature\n",
    "                if matching_activity:\n",
    "                    temperature = matching_activity.get('Temperature')\n",
    "            \n",
    "            # Use Temperature from activity if it exists and no matching activity was found\n",
    "            if temperature is None:\n",
    "                temperature = activity.get('Temperature')\n",
    "            \n",
    "            # If there's a temperature value (from ActivityNumber or direct temperature), add to program\n",
    "            if temperature is not None and start_time is not None:\n",
    "                # Check for duplicates or conflicts\n",
    "                if start_time in program_dict[day]:\n",
    "                    if program_dict[day][start_time] != temperature:\n",
    "                        raise ValueError(f\"Conflicting temperatures for {day} at {start_time}: {program_dict[day][start_time]} vs {temperature}\")\n",
    "                else:\n",
    "                    program_dict[day][start_time] = temperature\n",
    "\n",
    "    # Sort the program by ISO weekday order and start time\n",
    "    result = []\n",
    "    for day in sorted(program_dict.keys(), key=iso_weekday):\n",
    "        for start_time in sorted(program_dict[day].keys()):\n",
    "            result.append({\n",
    "                'weekday': day,\n",
    "                'start_time': start_time,\n",
    "                'temp_set__degC': program_dict[day][start_time]\n",
    "            })\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70654f9-e3e0-4350-8a85-680ee962ce57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate HTML diff between two lists of dictionaries\n",
    "def generate_diff(previous, current):\n",
    "    \"\"\"Generate an HTML diff between two lists of dictionaries.\"\"\"\n",
    "    # Convert lists of dictionaries to JSON strings\n",
    "    previous_json = json.dumps(previous, indent=4) if previous else ''\n",
    "    current_json = json.dumps(current, indent=4) if current else ''\n",
    "\n",
    "    if previous_json == '':  # If there is no previous program\n",
    "        return f\"<span style='color: green;'>New: {current_json}</span>\"\n",
    "    elif current_json == '':  # If there is no current program\n",
    "        return f\"<span style='color: red;'>Removed: {previous_json}</span>\"\n",
    "\n",
    "    # Generate diff using difflib\n",
    "    diff = difflib.ndiff(previous_json.splitlines(), current_json.splitlines())\n",
    "    html_diff = []\n",
    "\n",
    "    for line in diff:\n",
    "        line = line.strip()  # Remove leading/trailing whitespace\n",
    "        if line.startswith('+ '):\n",
    "            html_diff.append(f\"<span style='color: green;'>{line[2:]}</span>\")  # Added lines in green\n",
    "        elif line.startswith('- '):\n",
    "            html_diff.append(f\"<span style='color: red; text-decoration: line-through;'>{line[2:]}</span>\")  # Removed lines in red\n",
    "        elif line.startswith('^'):  # Ignore lines starting with ^\n",
    "            continue\n",
    "        else:\n",
    "            html_diff.append(line[2:])  # Unchanged lines\n",
    "\n",
    "    return ''.join(html_diff)  # Join without breaks for HTML display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e7fe56-5218-4d03-86dd-ba4d4458aeb2",
   "metadata": {},
   "source": [
    "## Read program file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389baf3f-edce-497e-9adb-92fc1634b5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the file size in bytes\n",
    "file_size_bytes = os.path.getsize(file_path)\n",
    "\n",
    "# Convert file size to kilobytes, megabytes, etc. for better readability\n",
    "file_size_kb = file_size_bytes / 1024\n",
    "file_size_mb = file_size_kb / 1024\n",
    "file_size_gb = file_size_mb / 1024\n",
    "\n",
    "# Print the file size\n",
    "print(f\"File Size: {file_size_bytes} bytes ({file_size_kb:.2f} KB, {file_size_mb:.2f} MB, {file_size_gb:.2f} GB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5015bcd1-4d79-4ffc-aebc-1ac378c29a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Attempt to read the Parquet file\n",
    "try:\n",
    "    df_programs = pd.read_parquet(\n",
    "        file_path, \n",
    "        engine='pyarrow',\n",
    "        dtype_backend='numpy_nullable'\n",
    "        )\n",
    "    print(\"File was successfully read without specifying compression codec.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error reading file: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d332e66-67ed-49ff-811b-55195bbcea62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_programs.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68115290-b829-43a9-9fed-c7763672ef0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_programs.memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29918bf6-5141-471a-a5af-1745d64534d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the 'pseudonym' column to 'id' and set as index\n",
    "df_programs.rename(columns={'pseudonym': 'id'}, inplace=True)\n",
    "df_programs = df_programs.set_index(['id', 'zone_type', 'zone_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cfde72-356d-4ec9-b025-a2e87a95f8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(df_programs.index.get_level_values('id').unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75062f3e-fb0a-4643-baa6-5595b7f79144",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_programs.index.get_level_values('zone_type').unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb29557-f55f-4048-926b-9834ffd97fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_programs.reset_index()[['zone_type', 'zone_name']].drop_duplicates().values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f16432-7290-4aff-bf86-e07f9e6eaa25",
   "metadata": {},
   "source": [
    "## Delete duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2b0667-11eb-4a04-964f-7b49f7a04fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_count = df_programs.shape[0]  # Count before deletion\n",
    "df_programs = df_programs.drop_duplicates()\n",
    "print(f\"Number of identical program rows: {initial_count - df_programs.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9932c1-cb64-4540-b496-97b8cecaeb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_programs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dca163-7c6d-487a-9578-a0b2b9d9e8db",
   "metadata": {},
   "source": [
    "## Parse heating_program and heating_activities into active_program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1e82ab-40c1-4e6e-b3a0-8e34b10e28ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the new parsing logic that uses heating_activities if temperature is not embedded\n",
    "df_programs.loc[:,'active_program'] = df_programs.apply(\n",
    "    lambda row: parse_heating_program(row['heating_program'], row['heating_activities']) if pd.notna(row['heating_program']) and pd.notna(row['heating_activities']) else None, axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3210f389-2eb3-4f18-b003-c3c0df4c0427",
   "metadata": {},
   "source": [
    "## Select only CH programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667daca1-a820-4afc-b4c6-cf8979005594",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice\n",
    "df_ch_programs = df_programs.loc[idx[:,'CH',:],['heating_program', 'heating_activities', 'active_program', 'valid_from','valid_to']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dffb07-0490-438d-be91-ccd37a43bf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ch_programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b03b51-4704-4e22-b10c-5f1e7d3687a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ch_programs.groupby(['id', 'zone_type', 'zone_name']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca93f271-3ef7-4e02-8a14-a6859b43d06e",
   "metadata": {},
   "source": [
    "## Select only analyzed ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be19f87-8f3b-458f-9f94-c5d229cdc736",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_ids = [401632,\n",
    " 403603,\n",
    " 404873,\n",
    " 410260,\n",
    " 412715,\n",
    " 424197,\n",
    " 429011,\n",
    " 430062,\n",
    " 434931,\n",
    " 444964,\n",
    " 449134,\n",
    " 450298,\n",
    " 456638,\n",
    " 458000,\n",
    " 458852,\n",
    " 478667,\n",
    " 483173,\n",
    " 487126,\n",
    " 494233,\n",
    " 495906]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cded69-87ba-4ac1-be3c-e6d2bc6d87f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ch_programs_analysis = df_ch_programs.loc[df_ch_programs.index.get_level_values('id').isin(analysis_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1539d804-5d41-4b1d-9705-7dd616d90927",
   "metadata": {},
   "source": [
    "## Focus on real program changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc17568-22c3-455c-8ac6-d0d062820b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_intervals = df_ch_programs_analysis[df_ch_programs_analysis['valid_from'] > df_ch_programs_analysis['valid_to']]\n",
    "if not invalid_intervals.empty:\n",
    "    print(\"Invalid intervals found:\")\n",
    "    with pd.option_context('display.max_colwidth', None):\n",
    "        display(invalid_intervals)\n",
    "else:\n",
    "    print(\"No invalid intervals found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32101a11-754b-4af1-be77-76eaba79e299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure valid_from and valid_to are both datetime\n",
    "df_ch_programs_analysis.loc[:,'valid_from'] = pd.to_datetime(df_ch_programs_analysis['valid_from'])\n",
    "df_ch_programs_analysis.loc[:,'valid_to'] = pd.to_datetime(df_ch_programs_analysis['valid_to'])\n",
    "\n",
    "\n",
    "# Fill NaT in valid_to with valid_from of the next row within the same id\n",
    "# Resetting index to simplify access\n",
    "df_ch_programs_analysis = df_ch_programs_analysis.reset_index().sort_values(by=['id', 'valid_from'])\n",
    "\n",
    "for i in range(len(df_ch_programs_analysis) - 1):\n",
    "    current_row = df_ch_programs_analysis.iloc[i]\n",
    "    next_row = df_ch_programs_analysis.iloc[i + 1]\n",
    "    \n",
    "    # Check if the current row has a NaT valid_to and the next row has the same id\n",
    "    if pd.isna(current_row['valid_to']) and current_row['id'] == next_row['id']:\n",
    "        # Fill NaT with the valid_from of the next row\n",
    "        df_ch_programs_analysis.at[current_row.name, 'valid_to'] = next_row['valid_from']\n",
    "        print(f\"Filled NaT with the valid_from of the next row: {next_row['valid_from']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8d2286-46d2-4415-9631-30e8161c0e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ch_programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1f901b-84ed-4543-9af0-2bcd987ae698",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ch_programs_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9294c18b-79f3-4542-8d4e-57256d82d59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NaT with future date\n",
    "df_ch_programs_analysis.loc[:,'valid_to'] = df_ch_programs_analysis['valid_to'].fillna(pd.Timestamp('2100-12-31').tz_localize('Europe/Amsterdam'))\n",
    "\n",
    "# Create IntervalIndex using valid_from and valid_to\n",
    "df_ch_programs_analysis.loc[:,'valid_interval'] = pd.IntervalIndex.from_arrays(\n",
    "    df_ch_programs_analysis['valid_from'],  # do not use .values to keep the timezone info\n",
    "    df_ch_programs_analysis['valid_to']    # do not use .values to keep the timezone info\n",
    ")\n",
    "\n",
    "# Create a copy with specified MultiIndex and columns\n",
    "df_ch_programs_analysis = df_ch_programs_analysis.copy().reset_index()\n",
    "\n",
    "# Now set the MultiIndex [id, valid_interval]\n",
    "df_ch_programs_analysis.set_index(['id', 'valid_interval'], inplace=True)\n",
    "\n",
    "# Keep only 'zone_name' and 'active_program' (renamed to 'program')\n",
    "df_ch_programs_analysis = df_ch_programs_analysis[['zone_name', 'active_program', 'valid_from', 'valid_to']].rename(columns={'active_program': 'program'})\n",
    "\n",
    "# Remove duplicates\n",
    "initial_count = df_ch_programs_analysis.shape[0]  # Count before deletion\n",
    "df_ch_programs_analysis = df_ch_programs_analysis[~df_ch_programs_analysis.index.duplicated(keep='first')]  # Keep the first occurrence of duplicates\n",
    "print(f\"Number of program rows that are essentially the same: {initial_count - df_ch_programs_analysis.shape[0]}\")  # Count deleted rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b805b881-c7a4-46cf-ace3-6ea16174cf80",
   "metadata": {},
   "source": [
    "## Display changes in thermostat programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08794e6d-cc77-4f4a-b45a-fe249c267925",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ch_programs_analysis = df_ch_programs_analysis.sort_index()\n",
    "\n",
    "df_ch_programs_analysis = df_ch_programs_analysis.drop(columns='zone_name')\n",
    "\n",
    "# Prepare to hold the generated HTML diff\n",
    "df_ch_programs_analysis['previous_program'] = None\n",
    "df_ch_programs_analysis['diff'] = ''\n",
    "\n",
    "# Iterate through the DataFrame\n",
    "for i in range(1, len(df_ch_programs_analysis)):\n",
    "    current_row = df_ch_programs_analysis.iloc[i]\n",
    "    previous_row = df_ch_programs_analysis.iloc[i - 1]\n",
    "\n",
    "    # Check if the current and previous rows have the same id\n",
    "    if current_row.name[0] == previous_row.name[0]:  # Compare 'id' from MultiIndex\n",
    "        # Generate the HTML diff\n",
    "        previous_program = previous_row['program']\n",
    "        current_program = current_row['program']\n",
    "        \n",
    "        df_ch_programs_analysis.at[current_row.name, 'previous_program'] = previous_program\n",
    "        df_ch_programs_analysis.at[current_row.name, 'diff'] = generate_diff(previous_program, current_program)\n",
    "\n",
    "\n",
    "\n",
    "# Display the DataFrame with HTML rendering\n",
    "with pd.option_context('display.max_colwidth', None):\n",
    "    # Display only the relevant columns with HTML\n",
    "    display(HTML(df_ch_programs_analysis[['diff']].to_html(escape=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca5144f-c735-45be-922a-f339a4cb6559",
   "metadata": {},
   "source": [
    "## Write programs to parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5767159-ce53-4ea6-a730-0b8475767eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_ch_programs_analysis = df_ch_programs_analysis.drop(columns = ['previous_program', 'diff'])\n",
    "df_ch_programs_analysis_to_write = df_ch_programs_analysis.copy()\n",
    "df_ch_programs_analysis = df_ch_programs_analysis.drop(columns = ['valid_from', 'valid_to'])\n",
    "df_ch_programs_analysis_to_write['timezone'] = 'Europe/Amsterdam'\n",
    "df_ch_programs_analysis_to_write['valid_from'] = df_ch_programs_analysis_to_write['valid_from'].dt.tz_convert('UTC')\n",
    "df_ch_programs_analysis_to_write['valid_to'] = df_ch_programs_analysis_to_write['valid_to'].dt.tz_convert('UTC')\n",
    "df_ch_programs_analysis_to_write = df_ch_programs_analysis_to_write.reset_index().drop(columns=['valid_interval']).set_index(['id', 'valid_from','valid_to'])\n",
    "df_ch_programs_analysis_to_write.to_parquet(file_output_path, index=True, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f46e28-713e-439b-9932-79e011264410",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_colwidth', None):\n",
    "    display(df_ch_programs_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0715e301-76a2-486c-ae6d-226a6c5e9c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_colwidth', None):\n",
    "    display(df_ch_programs_analysis_to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80124ec2-5271-4b76-bfe2-94441838d069",
   "metadata": {},
   "source": [
    "## Plot thermostat programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5936f8-b46d-4fb5-ae81-5cadbd14729f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "Plot.plot_thermostat_programs(df_ch_programs_analysis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
