{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Brains4Buildings data extraction and backup\n",
    "\n",
    "This JupyterLabs notebook can be used download raw data from a Twomes database (see also [more information how to setup a Twomes server](https://github.com/energietransitie/twomes-backoffice-configuration#jupyterlab)).\n",
    "\n",
    "In particular, it has been set up to get data from the [Brains4Buildings data collection](https://www.energietransitiewindesheim.nl/brains4buildings2022/privacy/index.html).\n",
    "\n",
    "Don't forget to install the requirements listed in [requirements.txt](../requirements.txt) first!\n",
    "\n",
    "To complete data extraction, you also need to have downloaded [b4b-rawdata.zip from the source](https://liveadminwindesheim.sharepoint.com/:u:/r/sites/O365-Brains4Buildings/Gedeelde%20documenten/General/Windesheim%20as%20Living%20Lab/data-raw-anon/b4b-rawdata.zip?csf=1&web=1&e=M0NX1r) and saved it in the ../data/ folder)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setting the stage\n",
    "\n",
    "First several imports and variables need to be defined\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and generic settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "import math\n",
    "import pylab as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# usually, two decimals suffice for displaying DataFrames (NB internally, precision may be higher)\n",
    "pd.options.display.precision = 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../data/')\n",
    "\n",
    "%load_ext autoreload\n",
    "import gc\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "from measurements import Measurements\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, \n",
    "                    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    filename='log_b4b.txt',\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining which account, which period \n",
    "\n",
    "- which account was used to provision the measurements? \n",
    "- the location and timezone is\n",
    "- from which `start_day` to which `end_day' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#location: T-building, Windesheim, in Zwolle\n",
    "lat, lon = 52.4350486, 5.4040816\n",
    "\n",
    "#timezone: \n",
    "timezone_database = 'UTC'\n",
    "timezone_buildings = 'Europe/Amsterdam'\n",
    "\n",
    "# Below, the maximum period for data collection\n",
    "first_day = pytz.timezone(timezone_buildings).localize(datetime(2022, 10, 1))\n",
    "last_day = pytz.timezone(timezone_buildings).localize(datetime(2022, 11, 2))\n",
    "\n",
    "# all devices were provisioned by a single account\n",
    "account = [820921]\n",
    "\n",
    "rooms = [999169, 900846, 948634, 917810, 925038, 924038]\n",
    "\n",
    "\n",
    "\n",
    "device_mapping = {\n",
    "    'TWOMES-979368': 999169,\n",
    "    'TWOMES-9799B8': 900846,\n",
    "    'TWOMES-ACDEF0': 948634,\n",
    "    'TWOMES-ACEB08': 917810,\n",
    "    'TWOMES-ACEB4C': 925038\n",
    "}\n",
    "\n",
    "rooms = [device_mapping[id] for id in device_mapping.keys()]\n",
    "rooms.append(924038)\n",
    "\n",
    "property_rename = {\n",
    "    'CO2concentration': 'co2__ppm',\n",
    "    'countPresence': 'occupancy__p',\n",
    "    'relativeHumidity': 'rel_humidity__0',\n",
    "    'roomTemp': 'temp_in__degC'\n",
    "}\n",
    "\n",
    "b4b_db_properties = list(property_rename.keys())\n",
    "\n",
    "property_types = {\n",
    "    'temp_in__degC' : 'float32',\n",
    "    'co2__ppm' : 'float32',\n",
    "    'rel_humidity__0' : 'float32',\n",
    "    'valve_frac__0' : 'float32',\n",
    "    'door_open__bool': 'Int8',\n",
    "    'window_open__bool': 'Int8',\n",
    "    'occupancy__bool': 'Int8',\n",
    "    'occupancy__p' : 'Int8'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting measurements from sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting measurements from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "%autoreload 2\n",
    "df_db_meas = (Measurements.get_raw_measurements(\n",
    "    account,\n",
    "    first_day, last_day,\n",
    "    b4b_db_properties,\n",
    "    timezone_database, timezone_buildings)\n",
    "           .loc[account[0]]\n",
    "           .rename(index=device_mapping)\n",
    "           .rename(index=property_rename)\n",
    "           .sort_index()\n",
    "          )\n",
    "\n",
    "df_db_meas.index.names = ['id', 'source', 'timestamp', 'property']\n",
    "df_db_meas = df_db_meas.loc[[device_mapping[id] for id in device_mapping.keys()]]\n",
    "# del df_db_meas['unit']\n",
    "df_db_meas.value = df_db_meas.value.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_db_meas.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_db_meas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get other measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "df = pd.read_csv('../data/b4b-rawdata.zip', parse_dates=['timestamp'], index_col=['timezone', 'timestamp']).sort_index(level='timestamp')\n",
    "\n",
    "\n",
    "df_other_meas = pd.DataFrame()\n",
    "for tz in df.index.unique(level='timezone'):\n",
    "    df_other_meas = pd.concat([df_other_meas, df.loc[tz].tz_localize(tz, ambiguous='NaT')])\n",
    "\n",
    "\n",
    "df_other_meas = df_other_meas.sort_index()\n",
    "\n",
    "df_other_meas = df_other_meas.loc[df_other_meas.index.dropna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_other_meas.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_other_meas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge database and other measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meas = (pd.concat([\n",
    "    df_db_meas.reset_index(), \n",
    "    df_other_meas.reset_index()[['id', 'source', 'timestamp', 'property', 'value']]\n",
    "])\n",
    "           .drop_duplicates()\n",
    "           .set_index(['id', 'source', 'timestamp', 'property'])\n",
    "           .sort_index()\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meas.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Writing raw measurements to a parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "df_meas.to_parquet('b4b_raw_measurements.parquet', index=True, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write raw measurements per home to parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "for room_id in tqdm(list(df_meas.index.unique(level='id'))):\n",
    "    df_meas.xs(room_id, drop_level=False).to_parquet(f'{room_id}_raw_measurements.parquet', index=True, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put properties in separate columns, apply types and write parquet file(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unstacking might take a lot of memory, hence do it homw by home. example: unstacking entire Twomes dataset uses 32 GB memory\n",
    "del df_meas\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Writing raw properties per home to a parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%autoreload 2\n",
    "\n",
    "df_prop = pd.DataFrame()\n",
    "\n",
    "for room_id in tqdm(rooms):\n",
    "    df_prop_room = Measurements.to_properties(\n",
    "        pd.read_parquet(f'{room_id}_raw_measurements.parquet', engine='pyarrow'),\n",
    "        property_types\n",
    "    )\n",
    "    df_prop_room.to_parquet(f'{room_id}_raw_properties.parquet', index=True, engine='pyarrow')\n",
    "    df_prop = pd.concat([df_prop, df_prop_room]) \n",
    "    \n",
    "if not df_prop.index.is_monotonic_increasing:\n",
    "    df_prop = df_prop.sort_index()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prop.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Writing raw properties to a parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "df_prop.to_parquet('b4b_raw_properties.parquet', index=True, engine='pyarrow')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
