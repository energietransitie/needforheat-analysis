{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Brains4Buildings data extraction and backup\n",
    "\n",
    "This JupyterLabs notebook can be used download raw data from a Twomes database (see also [more information how to setup a Twomes server](https://github.com/energietransitie/twomes-backoffice-configuration#jupyterlab)).\n",
    "\n",
    "In particular, it has been set up to get data from the [Brains4Buildings data collection](https://www.energietransitiewindesheim.nl/brains4buildings2022/privacy/index.html).\n",
    "\n",
    "Don't forget to install the requirements listed in [requirements.txt](../requirements.txt) first!\n",
    "\n",
    "To complete data extraction, you also need to have downloaded [b4b-rawdata.zip from the source](https://liveadminwindesheim.sharepoint.com/:u:/r/sites/O365-Brains4Buildings/Gedeelde%20documenten/General/Windesheim%20as%20Living%20Lab/data-raw-anon/b4b-rawdata.zip?csf=1&web=1&e=M0NX1r) and saved it in the ../data/ folder)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setting the stage\n",
    "\n",
    "First several imports and variables need to be defined\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and generic settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (measurements.py, line 97)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[0;32m~\\Anaconda3\\envs\\new\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3460\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 18\u001b[1;36m\n\u001b[1;33m    from measurements import Measurements\u001b[1;36m\n",
      "\u001b[1;36m  File \u001b[1;32m~\\OneDrive - Windesheim Office365\\Desktop\\Job\\Project\\ET\\B4B\\code\\Git_version\\twomes-inverse-grey-box-analysis\\examples\\../data\\measurements.py:97\u001b[1;36m\u001b[0m\n\u001b[1;33m    match len(ids):\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# usually, two decimals suffice for displaying DataFrames (NB internally, precision may be higher)\n",
    "pd.options.display.precision = 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../data/')\n",
    "\n",
    "%load_ext autoreload\n",
    "import gc\n",
    "\n",
    "\n",
    "from measurements import Measurements\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, \n",
    "                    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    filename='log_b4b.txt',\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining which account, which period \n",
    "\n",
    "- which account was used to provision the measurements? \n",
    "- the location and timezone is\n",
    "- from which `start_day` to which `end_day' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#location: T-building, Windesheim, in Zwolle\n",
    "lat, lon = 52.4350486, 5.4040816\n",
    "\n",
    "#timezone: \n",
    "timezone_database = 'UTC'\n",
    "timezone_buildings = 'Europe/Amsterdam'\n",
    "\n",
    "# Below, the maximum period for data collection\n",
    "first_day = pytz.timezone(timezone_buildings).localize(datetime(2022, 10, 1))\n",
    "last_day = pytz.timezone(timezone_buildings).localize(datetime(2022, 11, 2))\n",
    "\n",
    "# all devices were provisioned by a single account\n",
    "account = [820921]\n",
    "\n",
    "device_mapping = {\n",
    "    'TWOMES-979368': 999169,\n",
    "    'TWOMES-9799B8': 900846,\n",
    "    'TWOMES-ACDEF0': 948634,\n",
    "    'TWOMES-ACEB08': 917810,\n",
    "    'TWOMES-ACEB4C': 925038\n",
    "}\n",
    "\n",
    "rooms = [device_mapping[id] for id in device_mapping.keys()]\n",
    "rooms.append(924038)\n",
    "\n",
    "property_rename = {\n",
    "    'CO2concentration': 'co2__ppm',\n",
    "    'countPresence': 'occupancy__p',\n",
    "    'relativeHumidity': 'rel_humidity__0',\n",
    "    'roomTemp': 'temp_in__degC'\n",
    "}\n",
    "\n",
    "b4b_db_properties = list(property_rename.keys())\n",
    "\n",
    "property_types = {\n",
    "    'temp_in__degC' : 'float32',\n",
    "    'co2__ppm' : 'float32',\n",
    "    'rel_humidity__0' : 'float32',\n",
    "    'valve_frac__0' : 'float32',\n",
    "    'door_open__bool': 'Int8',\n",
    "    'window_open__bool': 'Int8',\n",
    "    'occupancy__bool': 'Int8',\n",
    "    'occupancy__p' : 'Int8'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting measurements from sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting measurements from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "%autoreload 2\n",
    "df_db_meas = (Measurements.get_raw_measurements(\n",
    "    account,\n",
    "    first_day, last_day,\n",
    "    b4b_db_properties, property_rename,\n",
    "    timezone_database, timezone_buildings)\n",
    "           .loc[account[0]]\n",
    "           .rename(index=device_mapping)\n",
    "          )\n",
    "\n",
    "df_db_meas.index.names = ['id', 'source', 'timestamp', 'property']\n",
    "df_db_meas = df_db_meas.loc[[device_mapping[id] for id in device_mapping.keys()]]\n",
    "df_db_meas = df_db_meas.sort_index()\n",
    "df_db_meas.value = df_db_meas.value.astype('float')\n",
    "mask_rh = df_db_meas.index.get_level_values('property') == 'rel_humidity__0'\n",
    "df_db_meas.loc[mask_rh, 'value'] = df_db_meas.loc[mask_rh, 'value']/100\n",
    "df_db_meas['unit'] = df_db_meas['unit'].cat.add_categories('0')\n",
    "df_db_meas.loc[mask_rh, 'unit'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_db_meas.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_db_meas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get other measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "df = pd.read_csv('../data/b4b-rawdata.zip', parse_dates=['timestamp'], index_col=['timezone', 'timestamp']).sort_index(level='timestamp')\n",
    "\n",
    "\n",
    "df_other_meas = pd.DataFrame()\n",
    "for tz in df.index.unique(level='timezone'):\n",
    "    df_other_meas = pd.concat([df_other_meas, df.loc[tz].tz_localize(tz, ambiguous='NaT')])\n",
    "\n",
    "\n",
    "df_other_meas = df_other_meas.sort_index()\n",
    "\n",
    "df_other_meas = df_other_meas.loc[df_other_meas.index.dropna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_other_meas.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_other_meas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge database and other measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meas = (pd.concat([\n",
    "    df_db_meas.reset_index(), \n",
    "    df_other_meas.reset_index()[['id', 'source', 'timestamp', 'property', 'value']]\n",
    "])\n",
    "           .drop_duplicates()\n",
    "           .set_index(['id', 'source', 'timestamp', 'property'])\n",
    "           .sort_index()\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meas.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Writing raw measurements to a parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "df_meas.to_parquet('b4b_raw_measurements.parquet', index=True, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write raw measurements per home to parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "for room_id in tqdm(list(df_meas.index.unique(level='id'))):\n",
    "    df_meas.xs(room_id, drop_level=False).to_parquet(f'{room_id}_raw_measurements.parquet', index=True, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put properties in separate columns, apply types and write parquet file(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unstacking might take a lot of memory, hence do it homw by home. example: unstacking entire Twomes dataset uses 32 GB memory\n",
    "del df_meas\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Writing raw properties per home to a parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%autoreload 2\n",
    "\n",
    "df_prop = pd.DataFrame()\n",
    "\n",
    "for room_id in tqdm(rooms):\n",
    "    df_prop_room = Measurements.to_properties(\n",
    "        pd.read_parquet(f'{room_id}_raw_measurements.parquet', engine='pyarrow'),\n",
    "        property_types\n",
    "    )\n",
    "    df_prop_room.to_parquet(f'{room_id}_raw_properties.parquet', index=True, engine='pyarrow')\n",
    "    df_prop = pd.concat([df_prop, df_prop_room]) \n",
    "    \n",
    "if not df_prop.index.is_monotonic_increasing:\n",
    "    df_prop = df_prop.sort_index()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prop.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Writing raw properties to a parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "df_prop.to_parquet('b4b_raw_properties.parquet', index=True, engine='pyarrow')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
