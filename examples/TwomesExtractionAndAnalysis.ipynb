{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twomes interactive inverse grey-box analysis pipeline\n",
    "\n",
    "This Jupyter Labs notebook can be used to interactively test the Twomes inverse grey-box analysis pipeline, accessing data from a Twomes database (see also [more information how to setup a Twomes server](https://github.com/energietransitie/twomes-backoffice-configuration#jupyterlab)).\n",
    "Don't forget to install the requirements listed in [requirements.txt](../requirements.txt) first!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the stage\n",
    "\n",
    "First several imports and variables need to be defined\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and generic settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "import math\n",
    "import pylab as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('../data/')\n",
    "sys.path.append('../view/')\n",
    "sys.path.append('../analysis/')\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%matplotlib widget\n",
    "from plotter import Plot\n",
    "from filewriter import ExcelWriter as ex\n",
    "\n",
    "from extractor import WeatherExtractor, Extractor, Period\n",
    "\n",
    "from inversegreyboxmodel import Learner\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger('Twomes data extraction')\n",
    "logger.setLevel(logging.NOTSET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis settings\n",
    "\n",
    "- which `moving_horizon_duration` should be used for the annalysis\n",
    "- and various other global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_std_outliers = 3.0 # default for the multiplier of the the standard deviation; further out than this times the std, outliers are removed during preprocessing\n",
    "up_intv = '5min' # the default upsampling interval that is used before interpolation is done\n",
    "gap_n_intv = 11 # the default maximum number of consecutive NaNs to fill(one for each upsampling interval), i.e. valid measurement values (11+1)* 5 min = 1 hour apart apart will be bridget by interpolation, but not more\n",
    "sampling_interval = '15min' # the default interval on which interpolation will be done during preprocessing\n",
    "moving_horizon_duration_d = 7\n",
    "required_columns_for_sanity = ['home_id', 'T_out_e_avg_C', 'irradiation_hor_avg_W_p_m2', 'T_in_avg_C', 'gas_sup_avg_W', 'e_remaining_heat_avg_W', 'interval_s']\n",
    "sanity_threshold = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining which homes, which period \n",
    "\n",
    "- which `homes` should be analysed\n",
    "- what the location and timezone is of those homes (currently, we only support one location and timezone for a batch of homes) \n",
    "- from which `start_day` to which `end_day'  the analysis should run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#location: center of Assendorp neighbourhood in Zwolle\n",
    "lat, lon = 52.50655, 6.09961\n",
    "\n",
    "#timezone: \n",
    "timezone_database = 'UTC'\n",
    "timezone_homes = 'Europe/Amsterdam'\n",
    "\n",
    "# # # Below, the maximum period for data collection\n",
    "# first_day = pytz.timezone(timezone_homes).localize(datetime(2021, 10, 25))\n",
    "# last_day = pytz.timezone(timezone_homes).localize(datetime(2022, 5, 8))\n",
    "\n",
    "# Alternatively, you may want to test things only on a three week periode. This is a period with suitable weather and lots of homes with measurements.\n",
    "first_day = pytz.timezone(timezone_homes).localize(datetime(2022, 1, 3))\n",
    "last_day = pytz.timezone(timezone_homes).localize(datetime(2022, 1, 31))\n",
    "\n",
    "# The full set of homes\n",
    "# homes = [803422, 805164, 809743, 811308, 815925, 817341, 822479, 829947, 830088, 831062, 839440, 845966, 845997, 846697, 857477, 864296, 873985, 879481, 881611, 886307, 895671, 897349, 899510]\n",
    "\n",
    "# # A subset of homes\n",
    "# homes = [803422, 805164, 809743]\n",
    "\n",
    "# single home for virtual homes\n",
    "homes = [886307]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and geospatial interpolation of Dutch weather data\n",
    "\n",
    "Using an external library installaed via [requirements.txt](../requirements.txt), load and geospatially interpolate Dutch weather data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "%autoreload 2\n",
    "# get geospatially interpolated weather from KNMI\n",
    "# for Twomes, the Weather for all all homes studies can be approached by a single location\n",
    "# get the dataframe only once for all homes to save time\n",
    "tz_knmi='Europe/Amsterdam'\n",
    "\n",
    "df_weather = WeatherExtractor.get_interpolated_weather_nl(first_day, last_day, lat, lon, tz_knmi, timezone_homes, sampling_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check descriptive statisctics about the weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot weather data\n",
    "\n",
    "N.B. The resulting figure below can be manipulated interactively; hover with mouse for tips & tricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.setLevel(logging.NOTSET)\n",
    "Plot.temperature_and_power_one_home_plot('Weather in Assendorp, Zwolle',\n",
    "                                df_weather,\n",
    "                                temp_plot_dict = {'T_out_avg_C': 'orange', 'wind_avg_m_p_s': 'c', 'T_out_e_avg_C': 'b'},\n",
    "                                temp_plot_2nd_list = ['wind_avg_m_p_s'],\n",
    "                                power_plot_dict = {'irradiation_hor_avg_W_p_m2': 'y'},\n",
    "                                power_plot_2nd_list = ['irradiation_hor_avg_W_p_m2']\n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting time-interpolated home data from the Twomes database and combine with weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "df_data_homes = Extractor.get_preprocessed_homes_data(homes, first_day, last_day, timezone_database, timezone_homes,\n",
    "                                                      up_intv, gap_n_intv, sampling_interval, \n",
    "                                                      df_weather)\n",
    "logger.setLevel(logging.NOTSET)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional block to write interpolated data to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename_prefix = datetime.now().astimezone(pytz.timezone('Europe/Amsterdam')).replace(microsecond=0).isoformat().replace(\":\",\"\")\n",
    "# ex.write(df_data_homes, str('{0}-data_homes-{1}-{2}.xlsx'.format(filename_prefix, first_day.isoformat(),last_day.isoformat())))\n",
    "# Extractor.write_home_data_to_csv(df_data_homes, str('{0}-data_homes-{1}-{2}.csv'.format(filename_prefix, first_day.isoformat(),last_day.isoformat())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional block to get interpolated data from virtual homes in CSV files and combine with weather data already obtained\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time \n",
    "# %autoreload 2\n",
    "# logger.setLevel(logging.INFO)\n",
    "\n",
    "# homes = [\n",
    "#     60200, \n",
    "#     120100, \n",
    "#     150080, \n",
    "#     150100, \n",
    "#     200060, \n",
    "#     300040, \n",
    "#     400030, \n",
    "#     600020 \n",
    "# ]\n",
    "\n",
    "# # For virtual homes, only the following period is valid:\n",
    "# first_day = pytz.timezone(timezone_homes).localize(datetime(2022, 1, 3))\n",
    "# last_day = pytz.timezone(timezone_homes).localize(datetime(2022, 1, 24))\n",
    "\n",
    "# df_data_homes = pd.DataFrame()\n",
    "# for home_id in homes:\n",
    "#     df_data_homes = pd.concat([df_data_homes, Extractor.get_virtual_home_data_csv(str('../data/virtualhome_P{0}.csv'.format(home_id)), timezone_homes)], axis=0)\n",
    "\n",
    "# logger.setLevel(logging.NOTSET)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_homes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Present sanity metrics for the extracted data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional block to write the extracted data to a CSV file\n",
    "\n",
    "N.B. In a future version we consider using the Apache Parquet format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time \n",
    "# from tqdm import tqdm_notebook\n",
    "\n",
    "# %autoreload 2\n",
    "# filename_prefix = datetime.now().astimezone(pytz.timezone('Europe/Amsterdam')).replace(microsecond=0).isoformat().replace(\":\",\"\")\n",
    "\n",
    "# first_day = pytz.timezone(timezone_homes).localize(datetime(2021, 10, 25))\n",
    "# last_day = pytz.timezone(timezone_homes).localize(datetime(2022, 5, 8))\n",
    "\n",
    "# df_rawdata = pd.DataFrame()\n",
    "# home_iterator = tqdm_notebook(homes)\n",
    "\n",
    "# for home_id in home_iterator:\n",
    "#     # print('Processing ', home_id)\n",
    "#     extractor = Extractor(home_id, Period(first_day, last_day))\n",
    "#     df_rawdata = extractor.get_rawdata()\n",
    "#     df_rawdata.describe(include='all')\n",
    "#     Extractor.write_raw_data_to_csv(df_rawdata, str('{0}-rawdata_P{1}-{2}-{3}.csv'.format(filename_prefix, home_id, first_day.isoformat(),last_day.isoformat())))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn parameters using inverse grey-box analysis\n",
    "\n",
    "Most of the heavy lifting is done by the `learn_home_parameter_moving_horizon()` function, which again uses the [GEKKO Python](https://machinelearning.byu.edu/) dynamic optimization toolkit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "\n",
    "# Use one of the lines below to set the moving horizon duration used for analysis \n",
    "# moving_horizon_duration_d_analysis = 14\n",
    "moving_horizon_duration_d_analysis = moving_horizon_duration_d\n",
    "\n",
    "\n",
    "# learn the model parameters and write rerults an intermediate results to excel files\n",
    "df_results_model_parameters, df_results_tempsim = Learner.learn_home_parameter_moving_horizon(df_data_homes, \n",
    "                                                         n_std_outliers, up_intv, gap_n_intv, sampling_interval, \n",
    "                                                         moving_horizon_duration_d_analysis, \n",
    "                                                         req_col = required_columns_for_sanity, sanity_threshold = sanity_threshold,\n",
    "                                                         hint_A_m2=None, ev_type=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Show the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show learned model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show table of all learned model parameters of all homes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_model_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize results of all learned model parameters of all homes in one plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_results_model_parameters\n",
    " ['H_W_p_K']\n",
    " .reorder_levels(['start_horizon', 'home_id'])\n",
    " .unstack()\n",
    " .plot(kind='box', \n",
    "       rot=90, \n",
    "       title='H_W_p_K')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_results_model_parameters\n",
    " ['tau_h']\n",
    " .reorder_levels(['start_horizon', 'home_id'])\n",
    " .unstack()\n",
    " .plot(kind='box', \n",
    "       rot=90,\n",
    "       title='tau_h')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_results_model_parameters['C_Wh_p_K'] = df_results_model_parameters['H_W_p_K'] * df_results_model_parameters['tau_h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_results_model_parameters\n",
    " ['C_Wh_p_K']\n",
    " .reorder_levels(['start_horizon', 'home_id'])\n",
    " .unstack()\n",
    " .plot(kind='box', \n",
    "       rot=90, \n",
    "       title='C_Wh_p_K')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize results of all learned model parameters by week for each home multiple plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "Plot.learned_parameters_plot(df_results_model_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show best fitting simulated temperatures and power flows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show table of best fitting simulated temperatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_tempsim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show a plot with the best fitting simulated temperatures and power flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "Plot.temperature_and_power_plot(df_results_tempsim,\n",
    "                                temp_plot_dict = {'T_out_avg_C': 'orange', 'wind_avg_m_p_s': 'c', 'T_out_e_avg_C': 'b', 'T_in_avg_C': 'red', 'T_set_first_C': 'pink', 'T_in_sim_avg_C': 'green'},\n",
    "                                temp_plot_2nd_list = ['wind_avg_m_p_s'],\n",
    "                                power_plot_dict = {'irradiation_hor_avg_W_p_m2': 'y', 'gas_sup_CH_avg_W': 'brown'},\n",
    "                                power_plot_2nd_list = ['irradiation_hor_avg_W_p_m2']\n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot a series of weeks for a single home homes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "home_id = 886307\n",
    "\n",
    "Plot.temperature_and_power_one_home_weekly_plot(home_id,\n",
    "                                                df_results_tempsim.loc[home_id],\n",
    "                                                sanity_threshold = sanity_threshold,\n",
    "                                                temp_plot_dict = {'T_out_avg_C': 'orange', 'wind_avg_m_p_s': 'c', 'T_out_e_avg_C': 'b', 'T_in_avg_C': 'red', 'T_set_first_C': 'pink', 'T_in_sim_avg_C': 'green'},\n",
    "                                                temp_plot_2nd_list = ['wind_avg_m_p_s'],\n",
    "                                                power_plot_dict = {'irradiation_hor_avg_W_p_m2': 'y', 'gas_sup_CH_avg_W': 'brown'},\n",
    "                                                power_plot_2nd_list = ['irradiation_hor_avg_W_p_m2']\n",
    "                                               )   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
